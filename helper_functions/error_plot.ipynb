{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# top_n_err_save_path = '../Analysis_Results/storage_server/All_models_res/error_analysis/final_results_all_models_top_n_err.csv'  # Replace with your CSV file name\n",
    "top_n_err_save_path = '../storage_server/COLM_res_update/All_Models_res/error_analysis/final_results_all_models_top_n_err_by_model.csv'\n",
    "df = pd.read_csv(top_n_err_save_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns  # Import Seaborn for enhanced visualization\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(dpi=400)\n",
    "\n",
    "# Assuming 'top_n_errors' is your DataFrame\n",
    "groupby_keys = ['model_name']\n",
    "n = 5  # Number of top categories to display\n",
    "top_n_errors = df\n",
    "\n",
    "# Specific order for the models\n",
    "model_order = [\n",
    "    \"gpt-4-turbo\", \"claude-3-opus-20240229\", \"claude-3-sonnet-20240229\", \n",
    "    \"claude-3-haiku-20240307\", \"Meta-Llama-3-70B-Instruct\", \"gpt-3.5-turbo-0125\",\n",
    "    \"Meta-Llama-3-8B-Instruct\", \"deepseek-coder-7b-instruct\", \"deepseek-coder-1.3b-instruct\", \n",
    "    \"phi-3-mini-4k\"\n",
    "]\n",
    "\n",
    "# Use a Seaborn palette for a better color choice\n",
    "palette = sns.color_palette(\"husl\", n_colors=len(top_n_errors['error_category'].unique()))\n",
    "\n",
    "# Sort the error_categories for consistent ordering\n",
    "sorted_error_categories = sorted(top_n_errors['error_category'].unique())\n",
    "\n",
    "# Determine the layout of subplots\n",
    "num_groups = len(top_n_errors.groupby(groupby_keys))\n",
    "cols = 2  # Number of columns in the subplot grid\n",
    "rows = (num_groups + cols - 1) // cols  # Calculate rows needed, ensuring at least 1\n",
    "\n",
    "# Create a figure to hold the subplots\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(20, 7 * rows), dpi=120, facecolor='white', sharey=True)\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.2)  # Adjust space between plots\n",
    "\n",
    "# Flatten the axs array if there's more than one row\n",
    "if rows > 1:\n",
    "    axs = axs.flatten()\n",
    "else:\n",
    "    axs = [axs]\n",
    "\n",
    "# Iterate over the models in the specified order\n",
    "for ax, model_name in zip(axs, model_order):\n",
    "    mask = top_n_errors['model_name'] == model_name\n",
    "    group_df = top_n_errors.loc[mask].copy()\n",
    "    \n",
    "    group_df['error_category'] = pd.Categorical(group_df['error_category'], categories=sorted_error_categories, ordered=True)\n",
    "    group_df.sort_values('error_category', inplace=True)\n",
    "    \n",
    "    sns.barplot(x='error_category', y='error_percentage', data=group_df, ax=ax, palette=palette)\n",
    "    \n",
    "    ax.set_ylabel('Percentage', fontsize=14)\n",
    "    ax.set_xlabel('Output Category', fontsize=14)\n",
    "    ax.set_title(f'Top {n} Output Categories for {model_name}', fontsize=16)\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "# Hide any unused axes if the number of plots is not a perfect fill of the grid\n",
    "for ax in axs[len(model_order):]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "# Create a legend for the error categories, added to the last plot\n",
    "legend_handles = [plt.Line2D([0], [0], marker='o', color='w', label=category, \n",
    "                            markerfacecolor=palette[i], markersize=10) for i, category in enumerate(sorted_error_categories)]\n",
    "axs[-1].legend(handles=legend_handles, title=\"Error Categories\", bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12, title_fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming 'top_n_errors' is your DataFrame and 'n' is the number of top categories to display\n",
    "n = 5\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Define a fixed color palette for all categories, ensuring consistency across plots\n",
    "unique_categories = top_n_errors['error_category'].unique()\n",
    "unique_categories_sorted = sorted(unique_categories, key=lambda x: (x != 'success', x))  # 'success' first, then alphabetically\n",
    "palette = sns.color_palette(\"husl\", len(unique_categories))\n",
    "\n",
    "# Map each category to a color\n",
    "category_color_map = {category: color for category, color in zip(unique_categories_sorted, palette)}\n",
    "\n",
    "# Specific order for the models\n",
    "model_order = [\n",
    "    \"gpt-4-turbo\", \"claude-3-opus-20240229\", \"claude-3-sonnet-20240229\", \n",
    "    \"claude-3-haiku-20240307\", \"Meta-Llama-3-70B-Instruct\", \"gpt-3.5-turbo-0125\",\n",
    "    \"Meta-Llama-3-8B-Instruct\", \"deepseek-coder-7b-instruct\", \"deepseek-coder-1.3b-instruct\", \n",
    "    \"phi-3-mini-4k\"\n",
    "]\n",
    "\n",
    "# Filter 'top_n_errors' to only include models in 'model_order'\n",
    "top_n_errors = top_n_errors[top_n_errors['model_name'].isin(model_order)]\n",
    "\n",
    "# Ensure the models are plotted in the specified order by setting the 'model_name' column as a Categorical with the defined order\n",
    "top_n_errors['model_name'] = pd.Categorical(top_n_errors['model_name'], categories=model_order, ordered=True)\n",
    "\n",
    "# Sort 'top_n_errors' by 'model_name' to ensure the plot follows the specified order\n",
    "top_n_errors.sort_values('model_name', inplace=True)\n",
    "\n",
    "# Determine the layout of subplots\n",
    "num_groups = len(model_order)  # Use the length of 'model_order' instead of unique models in DataFrame\n",
    "cols = 2  # Number of columns in the subplot grid\n",
    "rows = (num_groups + cols - 1) // cols  # Calculate rows needed, ensuring at least 1\n",
    "\n",
    "# Create a figure to hold the subplots\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(20, 7 * rows), dpi=120, facecolor='white', sharey=True)\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.2)  # Adjust space between plots\n",
    "\n",
    "# Flatten the axs array if there's more than one row\n",
    "if rows > 1:\n",
    "    axs = axs.flatten()\n",
    "else:\n",
    "    axs = [axs]\n",
    "\n",
    "# Iterate over the models in the specified order\n",
    "for ax, model_name in zip(axs, model_order):\n",
    "    # Filter the DataFrame for the current model\n",
    "    group_df = top_n_errors[top_n_errors['model_name'] == model_name]\n",
    "    \n",
    "    # Filter out categories with zero or missing 'error_percentage'\n",
    "    group_df = group_df[group_df['error_percentage'].notnull() & (group_df['error_percentage'] > 0)]\n",
    "    \n",
    "    # Determine the top N categories for this group, ensuring 'success' is considered first\n",
    "    top_categories = group_df.groupby('error_category')['error_percentage'].sum().nlargest(n + 1).index\n",
    "    top_categories_sorted = sorted(top_categories, key=lambda x: (x != 'success', x))[:n]\n",
    "    \n",
    "    # Filter the DataFrame to include only the top N categories\n",
    "    group_df = group_df[group_df['error_category'].isin(top_categories_sorted)]\n",
    "    \n",
    "    # Ensure the categories are in the same order for each group\n",
    "    group_df['error_category'] = pd.Categorical(group_df['error_category'], categories=top_categories_sorted, ordered=True)\n",
    "    group_df.sort_values('error_category', inplace=True)\n",
    "\n",
    "    # Convert 'error_category' to string to avoid mapping issues with Categorical types\n",
    "    group_df['error_category_str'] = group_df['error_category'].astype(str)\n",
    "\n",
    "    # Use the mapped colors for each category, using the string representation for mapping\n",
    "    colors = group_df['error_category_str'].map(category_color_map).tolist()\n",
    "    # sns.barplot(y='error_percentage', data=group_df, ax=ax, palette=colors)\n",
    "    sns.barplot(x='error_category_str', y='error_percentage', data=group_df, ax=ax, palette=colors)\n",
    "\n",
    "\n",
    "    ax.set_ylabel('Percentage', fontsize=20)\n",
    "    ax.set_xlabel('Output Category', fontsize=20)\n",
    "    ax.set_title(f'{model_name}', fontsize=23)\n",
    "\n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=15)\n",
    "    ax.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "\n",
    "# Hide any unused axes if the number of plots is not a perfect fill of the grid\n",
    "for ax in axs[len(model_order):]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "axs[-1].legend(handles=legend_handles, title=\"Output Categories\", bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=20, title_fontsize=20)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_output.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_err_save_path = '../storage_server/COLM_res_update/All_Models_res/error_analysis/final_results_all_models_all_err_by_model.csv' \n",
    "df = pd.read_csv(all_err_save_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the option to display all rows and columns\n",
    "pd.set_option('display.max_rows', None)  # None means show all rows\n",
    "pd.set_option('display.max_columns', None)  # None means show all columns\n",
    "\n",
    "# Now, when you print the DataFrame, all rows and columns will be shown\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted code snippet with requested changes\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import re\n",
    "\n",
    "# Function to extract average and error bar from the 'error_percentage' column\n",
    "def extract_avg_and_err_bar(s):\n",
    "    match = re.search(r\"(\\d+\\.\\d+) ± (\\d+\\.\\d+)\", s)\n",
    "    if match:\n",
    "        return float(match.group(1)), float(match.group(2))\n",
    "    else:\n",
    "        return float(s), 0  # No error bar, return value as is\n",
    "\n",
    "def plot_errors(df, report_err_bar=True):\n",
    "    # Assuming 'df' is your DataFrame\n",
    "    # Define the specific errors to plot\n",
    "    errors_of_interest = [\"CompilationError\", \"IdetatioError\", \"SytaxError\", \"NameError\"]\n",
    "\n",
    "    # Set the aesthetic style of the plots\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    top_n_errors = df.copy()  # Work on a copy if df is not to be modified directly\n",
    "\n",
    "    # Original model names and their simplified display names\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Simplify model names in the DataFrame\n",
    "    top_n_errors['model_display_name'] = top_n_errors['model_name'].map(model_name_mapping)\n",
    "\n",
    "    # Define a fixed color palette for all display models\n",
    "    palette = sns.color_palette(\"husl\", len(model_name_mapping))\n",
    "\n",
    "    # Map each display model to a color\n",
    "    model_color_map = {display_name: color for display_name, color in zip(model_name_mapping.values(), palette)}\n",
    "\n",
    "    # Calculate the number of rows needed for 2 columns\n",
    "    num_rows = len(errors_of_interest) // 2 + len(errors_of_interest) % 2\n",
    "\n",
    "    # Create a figure to hold the subplots with 2 columns\n",
    "    fig, axs = plt.subplots(num_rows, 2, figsize=(20, 7 * num_rows), dpi=120, facecolor='white')\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.2)  # Adjust space between plots\n",
    "\n",
    "    # Flatten the axs array for easy iteration\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Error title correction mapping\n",
    "    error_title_correction = {\n",
    "        \"CompilationError\": \"Compilation Error\",\n",
    "        \"IdetatioError\": \"Indentation Error\",\n",
    "        \"SytaxError\": \"Syntax Error\",\n",
    "        \"NameError\": \"Name Error\"\n",
    "    }\n",
    "\n",
    "    for ax, error_type in zip(axs, errors_of_interest):\n",
    "        # Filter the DataFrame for the current error type\n",
    "        error_df = top_n_errors[top_n_errors['error_category'] == error_type].copy()\n",
    "        \n",
    "        # Sort error_df based on the display names' order in model_name_mapping\n",
    "        error_df['model_display_name'] = pd.Categorical(error_df['model_display_name'], categories=model_name_mapping.values(), ordered=True)\n",
    "        error_df.sort_values('model_display_name', inplace=True)\n",
    "\n",
    "        # Extract average and error bar values\n",
    "        error_df[['avg_error_percentage', 'error_bar']] = error_df['error_percentage'].apply(lambda x: pd.Series(extract_avg_and_err_bar(x)))\n",
    "\n",
    "        if report_err_bar:\n",
    "            for model_display_name, group in error_df.groupby('model_display_name'):\n",
    "                ax.errorbar(group['model_display_name'], group['avg_error_percentage'], yerr=group['error_bar'], fmt='o', color=model_color_map[model_display_name], label=model_display_name)\n",
    "        else:\n",
    "            sns.barplot(x='model_display_name', y='avg_error_percentage', data=error_df, ax=ax, palette=model_color_map)\n",
    "\n",
    "        ax.set_ylabel('Percentage', fontsize=20)\n",
    "        ax.set_xlabel('')  # Hide the x-label as requested\n",
    "        # Use the corrected error title for the plot title\n",
    "        corrected_error_title = error_title_correction.get(error_type, error_type)  # Fallback to original if not found\n",
    "        ax.set_title(f'{corrected_error_title}', fontsize=23)\n",
    "\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=15)\n",
    "        ax.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "        # Adjust y-axis limits based on the data of each subplot for better visualization\n",
    "        max_error_percentage = error_df['avg_error_percentage'].max()\n",
    "        ax.set_ylim(0, max_error_percentage + 5)  # Adding a buffer for better visualization\n",
    "\n",
    "    # Hide any unused axes if the number of plots is not a perfect fill of the grid\n",
    "    for ax in axs[len(errors_of_interest):]:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "    # Update legend handles for display model names\n",
    "    legend_handles = [mpatches.Patch(color=model_color_map[display_name], label=display_name) for display_name in model_name_mapping.values()]\n",
    "\n",
    "    # Add the legend to the figure instead of the last subplot to span across the width and be centered at the bottom\n",
    "    fig.legend(handles=legend_handles, title=\"Model Names\", loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=5, fontsize=20, title_fontsize=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('error_analysis_by_type.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_errors(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted code snippet with requested changes\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import re\n",
    "\n",
    "# Function to extract average and error bar from the 'error_percentage' column\n",
    "def extract_avg_and_err_bar(s):\n",
    "    match = re.search(r\"(\\d+\\.\\d+) ± (\\d+\\.\\d+)\", s)\n",
    "    if match:\n",
    "        return float(match.group(1)), float(match.group(2))\n",
    "    else:\n",
    "        return float(s), 0  # No error bar, return value as is\n",
    "\n",
    "def plot_errors(df, report_err_bar=True):\n",
    "    # Assuming 'df' is your DataFrame\n",
    "    # Define the specific errors to plot\n",
    "    errors_of_interest = [\"CompilationError\", \"IdetatioError\", \"SytaxError\", \"NameError\"]\n",
    "\n",
    "    # Set the aesthetic style of the plots\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    top_n_errors = df.copy()  # Work on a copy if df is not to be modified directly\n",
    "\n",
    "    # Original model names and their simplified display names\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Simplify model names in the DataFrame\n",
    "    top_n_errors['model_display_name'] = top_n_errors['model_name'].map(model_name_mapping)\n",
    "\n",
    "    # Define a fixed color palette for all display models\n",
    "    palette = sns.color_palette(\"husl\", len(model_name_mapping))\n",
    "\n",
    "    # Map each display model to a color\n",
    "    model_color_map = {display_name: color for display_name, color in zip(model_name_mapping.values(), palette)}\n",
    "\n",
    "    # Calculate the number of rows needed for 2 columns\n",
    "    num_rows = len(errors_of_interest) // 2 + len(errors_of_interest) % 2\n",
    "\n",
    "    # Create a figure to hold the subplots with 2 columns\n",
    "    fig, axs = plt.subplots(num_rows, 2, figsize=(20, 7 * num_rows), dpi=120, facecolor='white')\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.2)  # Adjust space between plots\n",
    "\n",
    "    # Flatten the axs array for easy iteration\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Error title correction mapping\n",
    "    error_title_correction = {\n",
    "        \"CompilationError\": \"Compilation Error\",\n",
    "        \"IdetatioError\": \"Indentation Error\",\n",
    "        \"SytaxError\": \"Syntax Error\",\n",
    "        \"NameError\": \"Name Error\"\n",
    "    }\n",
    "\n",
    "    for ax, error_type in zip(axs, errors_of_interest):\n",
    "        error_df = top_n_errors[top_n_errors['error_category'] == error_type].copy()\n",
    "        error_df['model_display_name'] = pd.Categorical(error_df['model_display_name'], categories=model_name_mapping.values(), ordered=True)\n",
    "        error_df.sort_values('model_display_name', inplace=True)\n",
    "        error_df[['avg_error_percentage', 'error_bar']] = error_df['error_percentage'].apply(lambda x: pd.Series(extract_avg_and_err_bar(x)))\n",
    "\n",
    "        if report_err_bar:\n",
    "            for model_display_name, group in error_df.groupby('model_display_name'):\n",
    "                ax.errorbar(group['model_display_name'], group['avg_error_percentage'], yerr=group['error_bar'], fmt='o', color=model_color_map[model_display_name], label=model_display_name)\n",
    "        else:\n",
    "            sns.barplot(x='model_display_name', y='avg_error_percentage', data=error_df, ax=ax, palette=model_color_map)\n",
    "\n",
    "        # Using seaborn's barplot to draw bars with error bars\n",
    "        sns.barplot(x='model_display_name', y='avg_error_percentage', data=error_df, ax=ax, palette=model_color_map, yerr=error_df['error_bar'] if report_err_bar else None)\n",
    "        ax.set_ylabel('Percentage', fontsize=20)\n",
    "        ax.set_xlabel('')  # Hide the x-label as requested\n",
    "        # Use the corrected error title for the plot title\n",
    "        corrected_error_title = error_title_correction.get(error_type, error_type)  # Fallback to original if not found\n",
    "        ax.set_title(f'{corrected_error_title}', fontsize=28, fontweight='bold')\n",
    "\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=15)\n",
    "        ax.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "        # Adjust y-axis limits based on the data of each subplot for better visualization\n",
    "        max_error_percentage = error_df['avg_error_percentage'].max()\n",
    "        ax.set_ylim(0, max_error_percentage + 5)  # Adding a buffer for better visualization\n",
    "\n",
    "    # Hide any unused axes if the number of plots is not a perfect fill of the grid\n",
    "    for ax in axs[len(errors_of_interest):]:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "    # Update legend handles for display model names\n",
    "    legend_handles = [mpatches.Patch(color=model_color_map[display_name], label=display_name) for display_name in model_name_mapping.values()]\n",
    "\n",
    "    # Add the legend to the figure instead of the last subplot to span across the width and be centered at the bottom\n",
    "    fig.legend(handles=legend_handles, title=\"Model Names\", loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=5, fontsize=20, title_fontsize=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('error_analysis_by_type.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_errors(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted code snippet with requested changes\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import re\n",
    "\n",
    "# Function to extract average and error bar from the 'error_percentage' column\n",
    "def extract_avg_and_err_bar(s):\n",
    "    match = re.search(r\"(\\d+\\.\\d+) ± (\\d+\\.\\d+)\", s)\n",
    "    if match:\n",
    "        return float(match.group(1)), float(match.group(2))\n",
    "    else:\n",
    "        return float(s), 0  # No error bar, return value as is\n",
    "\n",
    "def plot_errors(df, report_err_bar=True):\n",
    "    # Assuming 'df' is your DataFrame\n",
    "    # Define the specific errors to plot\n",
    "    errors_of_interest = [\"CompilationError\", \"IdetatioError\", \"SytaxError\", \"NameError\"]\n",
    "\n",
    "    # Set the aesthetic style of the plots\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    top_n_errors = df.copy()  # Work on a copy if df is not to be modified directly\n",
    "\n",
    "    # Original model names and their simplified display names\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "    }\n",
    "\n",
    "    # Simplify model names in the DataFrame\n",
    "    top_n_errors['model_display_name'] = top_n_errors['model_name'].map(model_name_mapping)\n",
    "\n",
    "    # Define a fixed color palette for the selected display models\n",
    "    palette = sns.color_palette(\"husl\", len(model_name_mapping))\n",
    "\n",
    "    # Map each display model to a color\n",
    "    model_color_map = {display_name: color for display_name, color in zip(model_name_mapping.values(), palette)}\n",
    "\n",
    "    # Calculate the number of rows needed for 2 columns\n",
    "    num_rows = len(errors_of_interest) // 2 + len(errors_of_interest) % 2\n",
    "\n",
    "    # Create a figure to hold the subplots with 2 columns\n",
    "    fig, axs = plt.subplots(num_rows, 2, figsize=(20, 7 * num_rows), dpi=120, facecolor='white')\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.2)  # Adjust space between plots\n",
    "\n",
    "    # Flatten the axs array for easy iteration\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Error title correction mapping\n",
    "    error_title_correction = {\n",
    "        \"CompilationError\": \"Compilation Error\",\n",
    "        \"IdetatioError\": \"Indentation Error\",\n",
    "        \"SytaxError\": \"Syntax Error\",\n",
    "        \"NameError\": \"Name Error\"\n",
    "    }\n",
    "\n",
    "    for ax, error_type in zip(axs, errors_of_interest):\n",
    "        error_df = top_n_errors[top_n_errors['error_category'] == error_type].copy()\n",
    "        error_df['model_display_name'] = pd.Categorical(error_df['model_display_name'], categories=model_name_mapping.values(), ordered=True)\n",
    "        error_df.sort_values('model_display_name', inplace=True)\n",
    "        error_df[['avg_error_percentage', 'error_bar']] = error_df['error_percentage'].apply(lambda x: pd.Series(extract_avg_and_err_bar(x)))\n",
    "\n",
    "        if report_err_bar:\n",
    "            for model_display_name, group in error_df.groupby('model_display_name'):\n",
    "                ax.errorbar(group['model_display_name'], group['avg_error_percentage'], yerr=group['error_bar'], fmt='o', color=model_color_map[model_display_name], label=model_display_name)\n",
    "        else:\n",
    "            sns.barplot(x='model_display_name', y='avg_error_percentage', data=error_df, ax=ax, palette=model_color_map)\n",
    "\n",
    "        # Using seaborn's barplot to draw bars with error bars\n",
    "        # sns.barplot(x='model_display_name', y='avg_error_percentage', data=error_df, ax=ax, palette=model_color_map, yerr=error_df['error_bar'] if report_err_bar else None)\n",
    "        sns.barplot(x='model_display_name', y='avg_error_percentage', data=error_df.head(4), ax=ax, palette=model_color_map, yerr=error_df.head(4)['error_bar'].values if report_err_bar else None)\n",
    "        \n",
    "        ax.set_ylabel('Percentage', fontsize=20)\n",
    "        ax.set_xlabel('')  # Hide the x-label as requested\n",
    "        # Use the corrected error title for the plot title\n",
    "        corrected_error_title = error_title_correction.get(error_type, error_type)  # Fallback to original if not found\n",
    "        ax.set_title(f'{corrected_error_title}', fontsize=23)\n",
    "\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=15)\n",
    "        ax.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "        # Adjust y-axis limits based on the data of each subplot for better visualization\n",
    "        max_error_percentage = error_df['avg_error_percentage'].max()\n",
    "        ax.set_ylim(0, max_error_percentage + 5)  # Adding a buffer for better visualization\n",
    "\n",
    "    # Hide any unused axes if the number of plots is not a perfect fill of the grid\n",
    "    for ax in axs[len(errors_of_interest):]:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "    # Update legend handles for display model names\n",
    "    legend_handles = [mpatches.Patch(color=model_color_map[display_name], label=display_name) for display_name in model_name_mapping.values()]\n",
    "\n",
    "    # Add the legend to the figure instead of the last subplot to span across the width and be centered at the bottom\n",
    "    fig.legend(handles=legend_handles, title=\"Model Names\", loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=4, fontsize=20, title_fontsize=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('error_analysis_by_type.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_errors(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adjusted code snippet with requested changes\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import re\n",
    "\n",
    "# Function to extract average and error bar from the 'error_percentage' column\n",
    "def extract_avg_and_err_bar(s):\n",
    "    match = re.search(r\"(\\d+\\.\\d+) ± (\\d+\\.\\d+)\", s)\n",
    "    if match:\n",
    "        return float(match.group(1)), float(match.group(2))\n",
    "    else:\n",
    "        return float(s), 0  # No error bar, return value as is\n",
    "\n",
    "def plot_errors(df, report_err_bar=True):\n",
    "    # Assuming 'df' is your DataFrame\n",
    "    # Define the specific errors to plot\n",
    "    errors_of_interest = [\"CompilationError\", \"IdetatioError\", \"SytaxError\", \"NameError\"]\n",
    "\n",
    "    # Set the aesthetic style of the plots\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    top_n_errors = df.copy()  # Work on a copy if df is not to be modified directly\n",
    "\n",
    "    # Original model names and their simplified display names\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Simplify model names in the DataFrame\n",
    "    top_n_errors['model_display_name'] = top_n_errors['model_name'].map(model_name_mapping)\n",
    "\n",
    "    # Define a fixed color palette for all display models\n",
    "    palette = sns.color_palette(\"husl\", len(model_name_mapping))\n",
    "\n",
    "    # Map each display model to a color\n",
    "    model_color_map = {display_name: color for display_name, color in zip(model_name_mapping.values(), palette)}\n",
    "\n",
    "    # Calculate the number of rows needed for 2 columns\n",
    "    num_rows = len(errors_of_interest) // 2 + len(errors_of_interest) % 2\n",
    "\n",
    "    # Create a figure to hold the subplots with 2 columns\n",
    "    fig, axs = plt.subplots(num_rows, 2, figsize=(20, 7 * num_rows), dpi=120, facecolor='white')\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.2)  # Adjust space between plots\n",
    "\n",
    "    # Flatten the axs array for easy iteration\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Error title correction mapping\n",
    "    error_title_correction = {\n",
    "        \"CompilationError\": \"Compilation Error\",\n",
    "        \"IdetatioError\": \"Indentation Error\",\n",
    "        \"SytaxError\": \"Syntax Error\",\n",
    "        \"NameError\": \"Name Error\"\n",
    "    }\n",
    "\n",
    "\n",
    "    for i, (ax, error_type) in enumerate(zip(axs, errors_of_interest)):\n",
    "        error_df = top_n_errors[top_n_errors['error_category'] == error_type].copy()\n",
    "        error_df['model_display_name'] = pd.Categorical(error_df['model_display_name'], categories=model_name_mapping.values(), ordered=True)\n",
    "        error_df.sort_values('model_display_name', inplace=True)\n",
    "        error_df[['avg_error_percentage', 'error_bar']] = error_df['error_percentage'].apply(lambda x: pd.Series(extract_avg_and_err_bar(x)))\n",
    "\n",
    "        if report_err_bar:\n",
    "            for model_display_name, group in error_df.groupby('model_display_name'):\n",
    "                ax.errorbar(group['model_display_name'], group['avg_error_percentage'], yerr=group['error_bar'], fmt='o', color=model_color_map[model_display_name], label=model_display_name)\n",
    "        else:\n",
    "            sns.barplot(x='model_display_name', y='avg_error_percentage', data=error_df, ax=ax, palette=model_color_map)\n",
    "\n",
    "        # Using seaborn's barplot to draw bars with error bars\n",
    "        sns.barplot(x='model_display_name', y='avg_error_percentage', data=error_df, ax=ax, palette=model_color_map, yerr=error_df['error_bar'] if report_err_bar else None)\n",
    "        ax.set_ylabel('Percentage', fontsize=20, fontweight='bold')\n",
    "        \n",
    "        # Remove x-axis labels for all subplots\n",
    "        ax.set_xlabel('')  # Hide the x-label for all plots\n",
    "        ax.set_xticklabels([])  # Hide x-tick labels\n",
    "\n",
    "        ax.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "        # Use the corrected error title for the plot title\n",
    "        corrected_error_title = error_title_correction.get(error_type, error_type)  # Fallback to original if not found\n",
    "        ax.set_title(f'{corrected_error_title}', fontsize=28, fontweight='bold')\n",
    "\n",
    "        # Adjust y-axis limits based on the data of each subplot for better visualization\n",
    "        max_error_percentage = error_df['avg_error_percentage'].max()\n",
    "        ax.set_ylim(0, max_error_percentage + 5)  # Adding a buffer for better visualization\n",
    "\n",
    "    # Hide any unused axes if the number of plots is not a perfect fill of the grid\n",
    "    for ax in axs[len(errors_of_interest):]:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "    # Update legend handles for display model names and make legend text bold\n",
    "    legend_handles = [mpatches.Patch(color=model_color_map[display_name], label=display_name) for display_name in model_name_mapping.values()]\n",
    "\n",
    "    # Add the legend to the figure instead of the last subplot to span across the width and be centered at the bottom\n",
    "    fig.legend(handles=legend_handles, title=\"Model Names\", loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=5, fontsize=23, title_fontsize=23)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('v2_error_analysis_by_type.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_errors(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re  # Import the re module for regular expressions\n",
    "\n",
    "# Function to extract average and error bar from the 'error_percentage' column\n",
    "def extract_avg_and_err_bar(s):\n",
    "    match = re.search(r\"(\\d+\\.\\d+) ± (\\d+\\.\\d+)\", s)\n",
    "    if match:\n",
    "        return float(match.group(1)), float(match.group(2))\n",
    "    else:\n",
    "        return float(s), 0  # No error bar, return value as is\n",
    "\n",
    "def plot_errors(df):\n",
    "    # Define errors of interest and their corrected titles\n",
    "    errors_of_interest = [\"CompilationError\", \"IdetatioError\", \"SytaxError\", \"NameError\", \"Output Mismatch\", \"Success\"]\n",
    "    error_title_correction = {\n",
    "        \"CompilationError\": \"Compilation Error\",\n",
    "        \"IdetatioError\": \"Indentation Error\",\n",
    "        \"SytaxError\": \"Syntax Error\",\n",
    "        \"NameError\": \"Name Error\",\n",
    "        \"Output Mismatch\": \"Tests Failed\",\n",
    "        \"Success\": \"Test Passed\"\n",
    "    }\n",
    "\n",
    "    # Filter DataFrame for errors of interest\n",
    "    df = df[df['error_category'].isin(errors_of_interest)]\n",
    "\n",
    "    # Map error names to their corrected titles\n",
    "    df['error_category'] = df['error_category'].map(error_title_correction)\n",
    "\n",
    "    # Extract average error percentage\n",
    "    df[['avg_error_percentage', 'error_bar']] = df['error_percentage'].apply(lambda x: pd.Series(extract_avg_and_err_bar(x)))\n",
    "\n",
    "    # Model name mapping with the desired order\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Reverse the model_name_mapping order\n",
    "    reversed_model_names = list(model_name_mapping.values())[::-1]\n",
    "    reversed_model_order = {name: i for i, name in enumerate(reversed_model_names)}\n",
    "\n",
    "    # Map model names in the DataFrame to their reversed order rank\n",
    "    df['model_rank'] = df['model_name'].map(model_name_mapping).map(reversed_model_order)\n",
    "\n",
    "    # Set the style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Create a stacked bar chart\n",
    "    bottom_values = [0] * len(reversed_model_names)  # Initialize bottom values for stacking\n",
    "    for error in errors_of_interest:\n",
    "        error_df = df[df['error_category'] == error_title_correction[error]].sort_values(by='model_rank')\n",
    "        plt.bar(error_df['model_rank'], error_df['avg_error_percentage'], label=error_title_correction[error], bottom=bottom_values)\n",
    "        bottom_values = [i + j for i, j in zip(bottom_values, error_df['avg_error_percentage'])]  # Update bottom values for next stack\n",
    "\n",
    "    plt.xticks(range(len(reversed_model_names)), reversed_model_names, rotation=45, ha=\"right\")\n",
    "    plt.ylabel('Error Percentage')\n",
    "    plt.xlabel('Model Name')\n",
    "    plt.title('Error Analysis by Category')\n",
    "    plt.legend(title='Error Category')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "plot_errors(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re  # Import the re module for regular expressions\n",
    "\n",
    "# Function to extract average and error bar from the 'error_percentage' column\n",
    "def extract_avg_and_err_bar(s):\n",
    "    match = re.search(r\"(\\d+\\.\\d+) ± (\\d+\\.\\d+)\", s)\n",
    "    if match:\n",
    "        return float(match.group(1)), float(match.group(2))\n",
    "    else:\n",
    "        return float(s), 0  # No error bar, return value as is\n",
    "\n",
    "def plot_errors(df):\n",
    "    # Define errors of interest and their corrected titles\n",
    "    errors_of_interest = [\"CompilationError\", \"IdetatioError\", \"SytaxError\", \"NameError\", \"Output Mismatch\", \"Success\"]\n",
    "    error_title_correction = {\n",
    "        \"CompilationError\": \"Compilation Error\",\n",
    "        \"IdetatioError\": \"Indentation Error\",\n",
    "        \"SytaxError\": \"Syntax Error\",\n",
    "        \"NameError\": \"Name Error\",\n",
    "        \"Output Mismatch\": \"Tests Failed\",\n",
    "        \"Success\": \"Test Passed\"\n",
    "    }\n",
    "\n",
    "    # Filter DataFrame for errors of interest\n",
    "    df = df[df['error_category'].isin(errors_of_interest)]\n",
    "\n",
    "    # Map error names to their corrected titles\n",
    "    df['error_category'] = df['error_category'].map(error_title_correction)\n",
    "\n",
    "    # Extract average error percentage\n",
    "    df[['avg_error_percentage', 'error_bar']] = df['error_percentage'].apply(lambda x: pd.Series(extract_avg_and_err_bar(x)))\n",
    "\n",
    "    # Model name mapping with the desired order\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Reverse the model_name_mapping order\n",
    "    reversed_model_names = list(model_name_mapping.values())[::-1]\n",
    "    reversed_model_order = {name: i for i, name in enumerate(reversed_model_names)}\n",
    "\n",
    "    # Map model names in the DataFrame to their reversed order rank\n",
    "    df['model_rank'] = df['model_name'].map(model_name_mapping).map(reversed_model_order)\n",
    "\n",
    "    # Set the style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot each error category as a separate line\n",
    "    for error in errors_of_interest:\n",
    "        error_df = df[df['error_category'] == error_title_correction[error]].sort_values(by='model_rank')\n",
    "        plt.plot(error_df['model_rank'], error_df['avg_error_percentage'], marker='o', label=error_title_correction[error])\n",
    "\n",
    "    plt.xticks(range(len(reversed_model_names)), reversed_model_names, rotation=45, ha=\"right\")\n",
    "    plt.ylabel('Error Percentage')\n",
    "    plt.xlabel('Model Name')\n",
    "    plt.title('Error Analysis by Category')\n",
    "    plt.legend(title='Error Category')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "plot_errors(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_errors_stacked(df):\n",
    "    # Define errors of interest and their corrected titles\n",
    "    errors_of_interest = [\"CompilationError\", \"IdetatioError\", \"SytaxError\", \"NameError\", \"Output Mismatch\", \"Success\"]\n",
    "    error_title_correction = {\n",
    "        \"CompilationError\": \"Compilation Error\",\n",
    "        \"IdetatioError\": \"Indentation Error\",\n",
    "        \"SytaxError\": \"Syntax Error\",\n",
    "        \"NameError\": \"Name Error\",\n",
    "        \"Output Mismatch\": \"Tests Failed\",\n",
    "        \"Success\": \"Test Passed\"\n",
    "    }\n",
    "\n",
    "    # Filter DataFrame for errors of interest\n",
    "    df = df[df['error_category'].isin(errors_of_interest)]\n",
    "\n",
    "    # Map error names to their corrected titles\n",
    "    df['error_category'] = df['error_category'].map(error_title_correction)\n",
    "\n",
    "    # Extract average error percentage\n",
    "    df['avg_error_percentage'] = df['error_percentage'].apply(lambda x: float(x.split(' ± ')[0]))\n",
    "\n",
    "    # Model name mapping with the desired order\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Reverse the model_name_mapping order\n",
    "    reversed_model_names = list(model_name_mapping.values())[::-1]\n",
    "    reversed_model_order = {name: i for i, name in enumerate(reversed_model_names)}\n",
    "\n",
    "    # Map model names in the DataFrame to their reversed order rank\n",
    "    df['model_rank'] = df['model_name'].map(model_name_mapping).map(reversed_model_order)\n",
    "\n",
    "    # Sort DataFrame by model rank and error category for stacking\n",
    "    df_sorted = df.sort_values(by=['model_rank', 'error_category'])\n",
    "\n",
    "    # Set the style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Initialize a previous sum array to keep track of the cumulative sums\n",
    "    prev_sum = np.zeros(len(reversed_model_names))\n",
    "\n",
    "    # Iterate over each error category in reverse to stack from bottom to top\n",
    "    for error in reversed(errors_of_interest):\n",
    "        current_values = []\n",
    "        for rank in range(len(reversed_model_names)):\n",
    "            if rank in df_sorted[df_sorted['error_category'] == error_title_correction[error]]['model_rank'].values:\n",
    "                current_values.append(df_sorted[(df_sorted['model_rank'] == rank) & (df_sorted['error_category'] == error_title_correction[error])]['avg_error_percentage'].values[0])\n",
    "            else:\n",
    "                current_values.append(0)\n",
    "        current_sum = prev_sum + np.array(current_values)\n",
    "        plt.fill_between(range(len(reversed_model_names)), prev_sum, current_sum, label=error_title_correction[error])\n",
    "        prev_sum = current_sum\n",
    "\n",
    "    plt.xticks(range(len(reversed_model_names)), reversed_model_names, rotation=45, ha=\"right\")\n",
    "    plt.ylabel('Cumulative Error Percentage')\n",
    "    plt.xlabel('Model Name')\n",
    "    plt.title('Cumulative Error Analysis by Category')\n",
    "    plt.legend(title='Error Category', loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "plot_errors_stacked(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_errors_stacked(df):\n",
    "    # Adding \"Others\" category\n",
    "    errors_of_interest = [\"CompilationError\", \"IdetatioError\", \"SytaxError\", \"NameError\", \"Output Mismatch\", \"Success\", \"Others\"]\n",
    "    error_title_correction = {\n",
    "        \"CompilationError\": \"Compilation Error\",\n",
    "        \"IdetatioError\": \"Indentation Error\",\n",
    "        \"SytaxError\": \"Syntax Error\",\n",
    "        \"NameError\": \"Name Error\",\n",
    "        \"Output Mismatch\": \"Tests Failed\",\n",
    "        \"Success\": \"Test Passed\",\n",
    "        \"Others\": \"Others\"\n",
    "    }\n",
    "\n",
    "    # Assuming 100% is the total for each model, calculate \"Others\" as 100 minus the sum of known errors\n",
    "    df['avg_error_percentage'] = df['error_percentage'].apply(lambda x: float(x.split(' ± ')[0]))\n",
    "    total_by_model = df.groupby('model_name')['avg_error_percentage'].sum().reset_index()\n",
    "    total_by_model['Others'] = 100 - total_by_model['avg_error_percentage']\n",
    "    others_df = total_by_model[['model_name', 'Others']]\n",
    "    others_df['error_category'] = 'Others'\n",
    "    others_df = others_df.rename(columns={'Others': 'avg_error_percentage'})\n",
    "    df = pd.concat([df, others_df[['model_name', 'error_category', 'avg_error_percentage']]])\n",
    "\n",
    "    # Map error names to their corrected titles\n",
    "    df['error_category'] = df['error_category'].map(error_title_correction)\n",
    "\n",
    "    # Continue with the existing setup\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Reverse the model_name_mapping order\n",
    "    reversed_model_names = list(model_name_mapping.values())[::-1]\n",
    "    reversed_model_order = {name: i for i, name in enumerate(reversed_model_names)}\n",
    "\n",
    "    # Map model names in the DataFrame to their reversed order rank\n",
    "    df['model_rank'] = df['model_name'].map(model_name_mapping).map(reversed_model_order)\n",
    "\n",
    "    # Sort DataFrame by model rank and error category for stacking\n",
    "    df_sorted = df.sort_values(by=['model_rank', 'error_category'])\n",
    "\n",
    "    # Set the style and color palette\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    palette = sns.color_palette(\"hls\", 7)\n",
    "\n",
    "    # Plotting with increased resolution\n",
    "    plt.figure(figsize=(12, 10), dpi=600)\n",
    "\n",
    "    # Initialize a previous sum array to keep track of the cumulative sums\n",
    "    prev_sum = np.zeros(len(reversed_model_names))\n",
    "\n",
    "    # Iterate over each error category in reverse to stack from bottom to top\n",
    "    for error in reversed(errors_of_interest):\n",
    "        current_values = []\n",
    "        for rank in range(len(reversed_model_names)):\n",
    "            if rank in df_sorted[df_sorted['error_category'] == error_title_correction[error]]['model_rank'].values:\n",
    "                current_values.append(df_sorted[(df_sorted['model_rank'] == rank) & (df_sorted['error_category'] == error_title_correction[error])]['avg_error_percentage'].values[0])\n",
    "            else:\n",
    "                current_values.append(0)\n",
    "        current_sum = prev_sum + np.array(current_values)\n",
    "        plt.fill_between(range(len(reversed_model_names)), prev_sum, current_sum, label=error_title_correction[error])\n",
    "        prev_sum = current_sum\n",
    "        \n",
    "    # Customize font sizes and styles\n",
    "    plt.xticks(range(len(reversed_model_names)), reversed_model_names, rotation=45, ha=\"right\", fontsize=20, fontweight='bold')\n",
    "    plt.yticks(fontsize=20, fontweight='bold')\n",
    "    plt.xlabel('Model Name', fontsize=20, fontweight='bold')\n",
    "    plt.ylabel('Cumulative Error Percentage', fontsize=20, fontweight='bold')\n",
    "    plt.title('Cumulative Error Analysis by Category', fontsize=23, fontweight='bold')\n",
    "\n",
    "    # Adjust legend\n",
    "    plt.legend(title='Error Category', loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=True, ncol=3, fontsize=20, title_fontsize='20')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "plot_errors_stacked(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_errors_stacked(df):\n",
    "    # Adding \"Others\" category\n",
    "    errors_of_interest = [\"CompilationError\", \"IdetatioError\", \"SytaxError\", \"NameError\", \"Output Mismatch\", \"Success\"]\n",
    "    error_title_correction = {\n",
    "        \"CompilationError\": \"Compilation Error\",\n",
    "        \"IdetatioError\": \"Indentation Error\",\n",
    "        \"SytaxError\": \"Syntax Error\",\n",
    "        \"NameError\": \"Name Error\",\n",
    "        \"Output Mismatch\": \"Tests Failed\",\n",
    "        \"Success\": \"Test Passed\",\n",
    "    }\n",
    "\n",
    "    # Assuming 100% is the total for each model, calculate \"Others\" as 100 minus the sum of known errors\n",
    "    df['avg_error_percentage'] = df['error_percentage'].apply(lambda x: float(x.split(' ± ')[0]))\n",
    "    total_by_model = df.groupby('model_name')['avg_error_percentage'].sum().reset_index()\n",
    "    total_by_model['Other'] = 100 - total_by_model['avg_error_percentage']\n",
    "    others_df = total_by_model[['model_name', 'Other']]\n",
    "    others_df['error_category'] = 'Other'\n",
    "    others_df = others_df.rename(columns={'Other': 'avg_error_percentage'})\n",
    "    df = pd.concat([df, others_df[['model_name', 'error_category', 'avg_error_percentage']]])\n",
    "\n",
    "    # Map error names to their corrected titles\n",
    "    df['error_category'] = df['error_category'].map(error_title_correction)\n",
    "\n",
    "    # Continue with the existing setup\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Reverse the model_name_mapping order\n",
    "    reversed_model_names = list(model_name_mapping.values())[::-1]\n",
    "    reversed_model_order = {name: i for i, name in enumerate(reversed_model_names)}\n",
    "\n",
    "    # Map model names in the DataFrame to their reversed order rank\n",
    "    df['model_rank'] = df['model_name'].map(model_name_mapping).map(reversed_model_order)\n",
    "\n",
    "    # Sort DataFrame by model rank and error category for stacking\n",
    "    df_sorted = df.sort_values(by=['model_rank', 'error_category'])\n",
    "\n",
    "    # Set the style and color palette\n",
    "    sns.set_style(\"white\")\n",
    "    palette = sns.color_palette(\"hls\", 7)\n",
    "    \n",
    "    # Ensure \"Test Passed\" starts with green by rotating the palette\n",
    "    green_index = palette.index(sns.color_palette(\"hls\", 7)[2])  # Assuming green is at index 2 in the hls palette\n",
    "    palette = palette[green_index:] + palette[:green_index]  # Rotate palette to start with green\n",
    "\n",
    "    # Adjust plot size and resolution\n",
    "    plt.figure(figsize=(20, 12), dpi=600)  # Increased plot size\n",
    "\n",
    "    # Initialize a previous sum array to keep track of the cumulative sums\n",
    "    prev_sum = np.zeros(len(reversed_model_names))\n",
    "\n",
    "    # Iterate over each error category in reverse to stack from bottom to top\n",
    "    for error in reversed(errors_of_interest):\n",
    "        current_values = []\n",
    "        for rank in range(len(reversed_model_names)):\n",
    "            if rank in df_sorted[df_sorted['error_category'] == error_title_correction[error]]['model_rank'].values:\n",
    "                current_values.append(df_sorted[(df_sorted['model_rank'] == rank) & (df_sorted['error_category'] == error_title_correction[error])]['avg_error_percentage'].values[0])\n",
    "            else:\n",
    "                current_values.append(0)\n",
    "        current_sum = prev_sum + np.array(current_values)\n",
    "        plt.fill_between(range(len(reversed_model_names)), prev_sum, current_sum, label=error_title_correction[error])\n",
    "        prev_sum = current_sum\n",
    "        \n",
    "    # Customize font sizes and styles\n",
    "    plt.xticks(range(len(reversed_model_names)), reversed_model_names, rotation=45, ha=\"right\", fontsize=20, fontweight='bold')\n",
    "    plt.yticks(fontsize=20, fontweight='bold')\n",
    "    plt.xlabel('Model Name', fontsize=20, fontweight='bold')\n",
    "    plt.ylabel('Cumulative Error Percentage', fontsize=20, fontweight='bold')\n",
    "    plt.title('Cumulative Error Analysis by Category', fontsize=23, fontweight='bold')\n",
    "\n",
    "    # Adjust legend to move it further downwards\n",
    "    plt.legend(title='Error Category', loc='upper center', bbox_to_anchor=(0.5, -0.2), fancybox=True, shadow=True, ncol=3, fontsize=20, title_fontsize='20')\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "plot_errors_stacked(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_errors_stacked(df):\n",
    "    # Adding \"Others\" category\n",
    "    errors_of_interest = [\"CompilationError\", \"IdetatioError\", \"SytaxError\", \"NameError\", \"Output Mismatch\", \"Success\"]\n",
    "    error_title_correction = {\n",
    "        \"CompilationError\": \"Compilation Error\",\n",
    "        \"IdetatioError\": \"Indentation Error\",\n",
    "        \"SytaxError\": \"Syntax Error\",\n",
    "        \"NameError\": \"Name Error\",\n",
    "        \"Output Mismatch\": \"Tests Failed\",\n",
    "        \"Success\": \"Test Passed\",\n",
    "    }\n",
    "\n",
    "    # Assuming 100% is the total for each model, calculate \"Others\" as 100 minus the sum of known errors\n",
    "    df['avg_error_percentage'] = df['error_percentage'].apply(lambda x: float(x.split(' ± ')[0]))\n",
    "    total_by_model = df.groupby('model_name')['avg_error_percentage'].sum().reset_index()\n",
    "    total_by_model['Other'] = 100 - total_by_model['avg_error_percentage']\n",
    "    others_df = total_by_model[['model_name', 'Other']]\n",
    "    others_df['error_category'] = 'Other'\n",
    "    others_df = others_df.rename(columns={'Other': 'avg_error_percentage'})\n",
    "    df = pd.concat([df, others_df[['model_name', 'error_category', 'avg_error_percentage']]])\n",
    "\n",
    "    # Map error names to their corrected titles\n",
    "    df['error_category'] = df['error_category'].map(error_title_correction)\n",
    "\n",
    "    # Continue with the existing setup\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Reverse the model_name_mapping order\n",
    "    reversed_model_names = list(model_name_mapping.values())[::-1]\n",
    "    reversed_model_order = {name: i for i, name in enumerate(reversed_model_names)}\n",
    "\n",
    "    # Map model names in the DataFrame to their reversed order rank\n",
    "    df['model_rank'] = df['model_name'].map(model_name_mapping).map(reversed_model_order)\n",
    "\n",
    "    # Sort DataFrame by model rank and error category for stacking\n",
    "    df_sorted = df.sort_values(by=['model_rank', 'error_category'])\n",
    "\n",
    "    # Set the style and color palette\n",
    "    sns.set_style(\"white\")\n",
    "    palette = sns.color_palette(\"Set2\", 7)\n",
    "    \n",
    "    # Ensure \"Test Passed\" starts with green by rotating the palette\n",
    "    green_index = palette.index(sns.color_palette(\"Set2\", 7)[2])  # Assuming green is at index 2 in the hls palette\n",
    "    palette = palette[green_index:] + palette[:green_index]  # Rotate palette to start with green\n",
    "\n",
    "    # Adjust plot size and resolution\n",
    "    plt.figure(figsize=(20, 12), dpi=600)  # Increased plot size\n",
    "\n",
    "    # Initialize a previous sum array to keep track of the cumulative sums\n",
    "    prev_sum = np.zeros(len(reversed_model_names))\n",
    "\n",
    "    # Iterate over each error category in reverse to stack from bottom to top\n",
    "    for error in reversed(errors_of_interest):\n",
    "        current_values = []\n",
    "        for rank in range(len(reversed_model_names)):\n",
    "            if rank in df_sorted[df_sorted['error_category'] == error_title_correction[error]]['model_rank'].values:\n",
    "                current_values.append(df_sorted[(df_sorted['model_rank'] == rank) & (df_sorted['error_category'] == error_title_correction[error])]['avg_error_percentage'].values[0])\n",
    "            else:\n",
    "                current_values.append(0)\n",
    "        current_sum = prev_sum + np.array(current_values)\n",
    "        # plt.fill_between(range(len(reversed_model_names)), prev_sum, current_sum, label=error_title_correction[error])\n",
    "        color = palette[errors_of_interest.index(error)]  # Use the custom palette\n",
    "        plt.fill_between(range(len(reversed_model_names)), prev_sum, current_sum, label=error_title_correction[error], color=color)\n",
    "        prev_sum = current_sum\n",
    "        \n",
    "    # Customize font sizes and styles\n",
    "    plt.xticks(range(len(reversed_model_names)), reversed_model_names, rotation=45, ha=\"right\", fontsize=20, fontweight='bold')\n",
    "    plt.yticks(fontsize=20, fontweight='bold')\n",
    "    plt.xlabel('Model Name', fontsize=20, fontweight='bold')\n",
    "    plt.ylabel('Cumulative Error Percentage', fontsize=20, fontweight='bold')\n",
    "    plt.title('Cumulative Error Analysis by Category', fontsize=23, fontweight='bold')\n",
    "\n",
    "    # Adjust legend to move it further downwards\n",
    "    plt.legend(title='Error Category', loc='upper center', bbox_to_anchor=(0.5, -0.2), fancybox=True, shadow=True, ncol=3, fontsize=20, title_fontsize='20')\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "plot_errors_stacked(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique model names\n",
    "unique_models = df['model_name'].unique()\n",
    "\n",
    "# Print the number of unique models\n",
    "print(f\"Found {len(unique_models)} unique models:\")\n",
    "\n",
    "# Print the unique model names (sorted alphabetically)\n",
    "sorted_unique_models = sorted(unique_models)\n",
    "for idx, model in enumerate(sorted_unique_models, 1):\n",
    "    print(f\"{idx}. {model}\")\n",
    "    \n",
    "# Create a new DataFrame with just the unique model names\n",
    "unique_models_df = pd.DataFrame({'model_name': sorted_unique_models})\n",
    "\n",
    "# For analysis, you can also get the count of each model\n",
    "model_counts = df['model_name'].value_counts().reset_index()\n",
    "model_counts.columns = ['model_name', 'count']\n",
    "print(\"\\nModel occurrence counts:\")\n",
    "print(model_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_errors_stacked(df):\n",
    "    # Define the new order and color mapping for errors\n",
    "    errors_of_interest = [\"Success\", \"Output Mismatch\", \"SytaxError\", \"NameError\", \"IdetatioError\", \"CompilationError\"]\n",
    "    error_title_correction = {\n",
    "        \"CompilationError\": \"Compilation Error\",\n",
    "        \"IdetatioError\": \"Indentation Error\",\n",
    "        \"SytaxError\": \"Syntax Error\",\n",
    "        \"NameError\": \"Name Error\",\n",
    "        \"Output Mismatch\": \"Tests Failed\",\n",
    "        \"Success\": \"Tests Passed\",\n",
    "    }\n",
    "\n",
    "    # Adjusting the DataFrame to include the \"Others\" category\n",
    "    df['avg_error_percentage'] = df['error_percentage'].apply(lambda x: float(x.split(' ± ')[0]))\n",
    "    total_by_model = df.groupby('model_name')['avg_error_percentage'].sum().reset_index()\n",
    "    total_by_model['Other'] = 100 - total_by_model['avg_error_percentage']\n",
    "    others_df = total_by_model[['model_name', 'Other']]\n",
    "    others_df['error_category'] = 'Other'\n",
    "    others_df = others_df.rename(columns={'Other': 'avg_error_percentage'})\n",
    "    df = pd.concat([df, others_df[['model_name', 'error_category', 'avg_error_percentage']]])\n",
    "\n",
    "    # Map error names to their corrected titles\n",
    "    df['error_category'] = df['error_category'].map(error_title_correction)\n",
    "\n",
    "    # Continue with the existing setup\n",
    "    # model_name_mapping = {\n",
    "    #     \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "    #     # \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "    #     \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "    #     \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "    #     \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "    #     \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "    #     \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "    #     \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "    #     \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "    #     \"phi-3-mini-4k\": \"Phi-3 Mini 4K 3.8B\",\n",
    "    #     \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "    # }\n",
    "   \n",
    "    model_name_mapping = {\n",
    "        \"claude-3-7-sonnet-latest-ext16k\": \"Claude3.7Sonnet-ET\",\n",
    "        \"o3-mini-2025-01-31\": \"o3-Mini(high)\",\n",
    "        \"gpt-4o-2024-08-06\": \"GPT-4o\",\n",
    "        \"DeepSeek-R1\": \"DeepSeek R1\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-7-sonnet-latest\": \"Claude-3.7 Sonnet\",\n",
    "        \"claude-3-5-haiku-latest\": \"Claude-3.5 Haiku\",\n",
    "        \"Qwen2-5-Coder-32B-Instruct\": \"Qwen2.5 Coder 32B\",\n",
    "\n",
    "        \"Meta-Llama-3-3-70B-Instruct\": \"Llama-3.3 70B\",\n",
    "        \"Qwen-QwQ-32B\": \"Qwen QwQ 32B\",\n",
    "        \"deepseek-ai-DeepSeek-R1-Distill-Qwen-14B\": \"R1 Distill QWen 14B\",\n",
    "        \"Meta-Llama-3-1-8B-Instruct-Turbo\": \"Llama-3.1 8B Turbo\",\n",
    "    }\n",
    "    # # Continue with the existing setup\n",
    "    # model_name_mapping = {\n",
    "    #     \"DeepSeek-R1\": \"DeepSeek R1\",\n",
    "    #     \"Meta-Llama-3-1-8B-Instruct-Turbo\": \"Llama-3.1 8B Turbo\",\n",
    "    #     \"Meta-Llama-3-3-70B-Instruct\": \"Llama-3.3 70B\",\n",
    "    #     \"Qwen-QwQ-32B\": \"Qwen-QwQ 32B\",\n",
    "    #     \"Qwen2-5-Coder-32B-Instruct\": \"Qwen2.5 Coder 32B\",\n",
    "    #     \"claude-3-5-haiku-latest\": \"Claude-3.5 Haiku\",\n",
    "    #     \"claude-3-7-sonnet-latest\": \"Claude-3.7 Sonnet\",\n",
    "    #     \"claude-3-7-sonnet-latest-ext16k\": \"Claude-3.7 Sonnet ET\",\n",
    "    #     \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "    #     \"deepseek-ai-DeepSeek-R1-Distill-Qwen-14B\": \"R1 Distill 14B\",\n",
    "    #     \"gpt-4o-2024-08-06\": \"GPT-4o\",\n",
    "    #     \"o3-mini-2025-01-31\": \"O3 Mini\"\n",
    "    # }\n",
    "\n",
    "    # Reverse the model_name_mapping order\n",
    "    reversed_model_names = list(model_name_mapping.values())[::-1]\n",
    "    reversed_model_order = {name: i for i, name in enumerate(reversed_model_names)}\n",
    "\n",
    "    # Map model names in the DataFrame to their reversed order rank\n",
    "    df['model_rank'] = df['model_name'].map(model_name_mapping).map(reversed_model_order)\n",
    "\n",
    "    # Sort DataFrame by model rank and error category for stacking\n",
    "    df_sorted = df.sort_values(by=['model_rank', 'error_category'])\n",
    "\n",
    "    # Set the style and select a specific color palette\n",
    "    sns.set_style(\"white\")\n",
    "    hls_palette = sns.color_palette(\"Set2\", 8)\n",
    "    custom_palette = [hls_palette[i] for i in [0, 3, 4, 5, 2, 1]]  # Custom order based on the provided indices\n",
    "\n",
    "    # Adjust plot size and resolution\n",
    "    plt.figure(figsize=(20, 12), dpi=600)\n",
    "\n",
    "    # Initialize a previous sum array to keep track of the cumulative sums\n",
    "    prev_sum = np.zeros(len(reversed_model_names))\n",
    "\n",
    "    # Iterate over each error category in reverse to stack from bottom to top\n",
    "    # for error in errors_of_interest:\n",
    "    #     current_values = []\n",
    "    #     for rank in range(len(reversed_model_names)):\n",
    "    #         if rank in df_sorted[df_sorted['error_category'] == error_title_correction[error]]['model_rank'].values:\n",
    "    #             current_values.append(df_sorted[(df_sorted['model_rank'] == rank) & (df_sorted['error_category'] == error_title_correction[error])]['avg_error_percentage'].values[0])\n",
    "    #         else:\n",
    "    #             current_values.append(0)\n",
    "    #     current_sum = prev_sum + np.array(current_values)\n",
    "    #     color = custom_palette[errors_of_interest.index(error)]  # Use the custom palette\n",
    "    #     plt.fill_between(range(len(reversed_model_names)), prev_sum, current_sum, label=error_title_correction[error], color=color)\n",
    "    #     prev_sum = current_sum\n",
    "    for error in errors_of_interest:\n",
    "        current_values = []\n",
    "        for rank in range(len(reversed_model_names)):\n",
    "            if rank in df_sorted[df_sorted['error_category'] == error_title_correction[error]]['model_rank'].values:\n",
    "                current_values.append(df_sorted[(df_sorted['model_rank'] == rank) & (df_sorted['error_category'] == error_title_correction[error])]['avg_error_percentage'].values[0])\n",
    "            else:\n",
    "                current_values.append(0)\n",
    "        current_sum = prev_sum + np.array(current_values)\n",
    "        color = custom_palette[errors_of_interest.index(error)]  # Use the custom palette\n",
    "        plt.fill_between(range(len(reversed_model_names)), prev_sum, current_sum, label=error_title_correction[error], color=color, edgecolor='white', linewidth=2)  # Added edgecolor and linewidth\n",
    "        prev_sum = current_sum\n",
    "        \n",
    "    # Customize font sizes and styles\n",
    "    plt.xticks(range(len(reversed_model_names)), reversed_model_names, rotation=45, ha=\"right\", fontsize=20, fontweight='bold')\n",
    "    plt.yticks(fontsize=20, fontweight='bold')\n",
    "    plt.xlabel('Model Name', fontsize=20, fontweight='bold')\n",
    "    plt.ylabel('Cumulative Output Percentage', fontsize=20, fontweight='bold')\n",
    "    plt.title('Cumulative Output by Category', fontsize=23, fontweight='bold')\n",
    "\n",
    "    # Adjust legend to move it further downwards\n",
    "    plt.legend(title='Output Category', loc='upper center', bbox_to_anchor=(0.5, -0.25), fancybox=True, shadow=True, ncol=3, fontsize=20, title_fontsize='20')\n",
    "\n",
    "    # Save the plot to a PNG file\n",
    "    plt.savefig('cumulative_output_by_category.png', bbox_inches='tight', dpi=1200)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "plot_errors_stacked(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_errors_stacked(df):\n",
    "    # Define the new order and color mapping for errors\n",
    "    errors_of_interest = [\"Success\", \"Output Mismatch\", \"SytaxError\", \"NameError\", \"IdetatioError\", \"CompilationError\"]\n",
    "    error_title_correction = {\n",
    "        \"CompilationError\": \"Compilation Error\",\n",
    "        \"IdetatioError\": \"Indentation Error\",\n",
    "        \"SytaxError\": \"Syntax Error\",\n",
    "        \"NameError\": \"Var Hallucination\",\n",
    "        \"Output Mismatch\": \"Tests Failed\",\n",
    "        \"Success\": \"Tests Passed\",\n",
    "    }\n",
    "\n",
    "    # Adjusting the DataFrame to include the \"Others\" category\n",
    "    df['avg_error_percentage'] = df['error_percentage'].apply(lambda x: float(x.split(' ± ')[0]))\n",
    "    total_by_model = df.groupby('model_name')['avg_error_percentage'].sum().reset_index()\n",
    "    total_by_model['Other'] = 100 - total_by_model['avg_error_percentage']\n",
    "    others_df = total_by_model[['model_name', 'Other']]\n",
    "    others_df['error_category'] = 'Other'\n",
    "    others_df = others_df.rename(columns={'Other': 'avg_error_percentage'})\n",
    "    df = pd.concat([df, others_df[['model_name', 'error_category', 'avg_error_percentage']]])\n",
    "\n",
    "    # Map error names to their corrected titles\n",
    "    df['error_category'] = df['error_category'].map(error_title_correction)\n",
    "\n",
    "    # Updated model name mapping in descending order of capability/size\n",
    "    model_name_mapping = {\n",
    "        \"claude-3-7-sonnet-latest-ext16k\": \"Claude3.7Sonnet-ET\",\n",
    "        \"o3-mini-2025-01-31\": \"o3-Mini(high)\",\n",
    "        \"gpt-4o-2024-08-06\": \"GPT-4o\",\n",
    "        \"DeepSeek-R1\": \"DeepSeek R1\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-7-sonnet-latest\": \"Claude-3.7 Sonnet\",\n",
    "        \"claude-3-5-haiku-latest\": \"Claude-3.5 Haiku\",\n",
    "        \"Qwen2-5-Coder-32B-Instruct\": \"Qwen2.5 Coder 32B\",\n",
    "\n",
    "        \"Meta-Llama-3-3-70B-Instruct\": \"Llama-3.3 70B\",\n",
    "        \"Qwen-QwQ-32B\": \"Qwen QwQ 32B\",\n",
    "        \"deepseek-ai-DeepSeek-R1-Distill-Qwen-14B\": \"R1 Distill QWen 14B\",\n",
    "        \"Meta-Llama-3-1-8B-Instruct-Turbo\": \"Llama-3.1 8B Turbo\",\n",
    "    }\n",
    "    # Reverse the model_name_mapping order\n",
    "    reversed_model_names = list(model_name_mapping.values())[::-1]\n",
    "    reversed_model_order = {name: i for i, name in enumerate(reversed_model_names)}\n",
    "\n",
    "    # Map model names in the DataFrame to their reversed order rank\n",
    "    df['model_rank'] = df['model_name'].map(model_name_mapping).map(reversed_model_order)\n",
    "\n",
    "    # Sort DataFrame by model rank and error category for stacking\n",
    "    df_sorted = df.sort_values(by=['model_rank', 'error_category'])\n",
    "\n",
    "    # Set the style and select a specific color palette\n",
    "    sns.set_style(\"whitegrid\")  # Changed to whitegrid for subtle grid lines\n",
    "    hls_palette = sns.color_palette(\"Set2\", 8)\n",
    "    custom_palette = [hls_palette[i] for i in [0, 3, 4, 5, 2, 1]]  # Custom order based on provided indices\n",
    "\n",
    "    # Adjust plot size and resolution\n",
    "    plt.figure(figsize=(20, 12), dpi=1200)  # Increased DPI from 600 to 1200\n",
    "\n",
    "    # Initialize a previous sum array to keep track of the cumulative sums\n",
    "    prev_sum = np.zeros(len(reversed_model_names))\n",
    "\n",
    "    # Iterate over each error category to stack\n",
    "    for error in errors_of_interest:\n",
    "        current_values = []\n",
    "        for rank in range(len(reversed_model_names)):\n",
    "            if rank in df_sorted[df_sorted['error_category'] == error_title_correction[error]]['model_rank'].values:\n",
    "                current_values.append(df_sorted[(df_sorted['model_rank'] == rank) & (df_sorted['error_category'] == error_title_correction[error])]['avg_error_percentage'].values[0])\n",
    "            else:\n",
    "                current_values.append(0)\n",
    "        current_sum = prev_sum + np.array(current_values)\n",
    "        color = custom_palette[errors_of_interest.index(error)]\n",
    "        plt.fill_between(range(len(reversed_model_names)), prev_sum, current_sum, \n",
    "                         label=error_title_correction[error], \n",
    "                         color=color, \n",
    "                         edgecolor='white', \n",
    "                         linewidth=1.5,  # Refined line width for better definition\n",
    "                         alpha=0.95)     # Slight transparency for better visual\n",
    "        prev_sum = current_sum\n",
    "\n",
    "    # Add subtle grid lines for better readability\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "        \n",
    "    # Enhance text and label styling\n",
    "    plt.xticks(range(len(reversed_model_names)), reversed_model_names, rotation=45, ha=\"right\", fontsize=22, fontweight='bold')\n",
    "    plt.yticks(fontsize=22, fontweight='bold')\n",
    "    plt.xlabel('Model Name', fontsize=24, fontweight='bold')\n",
    "    plt.ylabel('Cumulative Output Percentage', fontsize=24, fontweight='bold')\n",
    "    plt.title('Cumulative Output by Category', fontsize=26, fontweight='bold')\n",
    "\n",
    "    # Enhance legend appearance\n",
    "    plt.legend(title='Output Category', \n",
    "               loc='upper center', \n",
    "               bbox_to_anchor=(0.5, -0.4), \n",
    "               fancybox=True, \n",
    "               shadow=True, \n",
    "               ncol=3, \n",
    "               fontsize=22, \n",
    "               title_fontsize=24)\n",
    "\n",
    "    # Save with higher resolution\n",
    "    plt.savefig('cumulative_output_by_category.png', \n",
    "                bbox_inches='tight', \n",
    "                dpi=1200,           # Increased DPI for saved file\n",
    "                pad_inches=0.5)     # Slightly more padding\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "plot_errors_stacked(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_err_save_path = '../Analysis_Results/storage_server/All_models_res/error_analysis/final_results_all_models_all_err_by_model.csv' \n",
    "df = pd.read_csv(all_err_save_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_errors_stacked(df):\n",
    "    # Adding \"Others\" category\n",
    "    errors_of_interest = [\"CompilationError\", \"IdetatioError\", \"SytaxError\", \"NameError\", \"Output Mismatch\", \"Success\"]\n",
    "    error_title_correction = {\n",
    "        \"CompilationError\": \"Compilation Error\",\n",
    "        \"IdetatioError\": \"Indentation Error\",\n",
    "        \"SytaxError\": \"Syntax Error\",\n",
    "        \"NameError\": \"Name Error\",\n",
    "        \"Output Mismatch\": \"Tests Failed\",\n",
    "        \"Success\": \"Test Passed\",\n",
    "    }\n",
    "\n",
    "    # Assuming 100% is the total for each model, calculate \"Others\" as 100 minus the sum of known errors\n",
    "    df['avg_error_percentage'] = df['error_percentage'].apply(lambda x: float(x.split(' ± ')[0]))\n",
    "    total_by_model = df.groupby('model_name')['avg_error_percentage'].sum().reset_index()\n",
    "    total_by_model['Other'] = 100 - total_by_model['avg_error_percentage']\n",
    "    others_df = total_by_model[['model_name', 'Other']]\n",
    "    others_df['error_category'] = 'Other'\n",
    "    others_df = others_df.rename(columns={'Other': 'avg_error_percentage'})\n",
    "    df = pd.concat([df, others_df[['model_name', 'error_category', 'avg_error_percentage']]])\n",
    "\n",
    "    # Map error names to their corrected titles\n",
    "    df['error_category'] = df['error_category'].map(error_title_correction)\n",
    "\n",
    "    # Continue with the existing setup\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Reverse the model_name_mapping order\n",
    "    reversed_model_names = list(model_name_mapping.values())[::-1]\n",
    "    reversed_model_order = {name: i for i, name in enumerate(reversed_model_names)}\n",
    "\n",
    "    # Map model names in the DataFrame to their reversed order rank\n",
    "    df['model_rank'] = df['model_name'].map(model_name_mapping).map(reversed_model_order)\n",
    "\n",
    "    # Sort DataFrame by model rank and error category for stacking\n",
    "    df_sorted = df.sort_values(by=['model_rank', 'error_category'])\n",
    "\n",
    "    # Set the style and color palette\n",
    "    # Set the style and select a better color palette, ensuring \"Tests Passed\" is green and \"Tests Failed\" is red\n",
    "    sns.set_style(\"white\")\n",
    "    palette = [\"#3498db\", \"#e74c3c\", \"#2ecc71\", \"#9b59b6\", \"#34495e\", \"#f1c40f\", \"#95a5a6\"]  # Custom palette\n",
    "\n",
    "    \n",
    "    # # Ensure \"Test Passed\" starts with green by rotating the palette\n",
    "    # green_index = palette.index(sns.color_palette(\"hls\", 7)[2])  # Assuming green is at index 2 in the hls palette\n",
    "    # palette = palette[green_index:] + palette[:green_index]  # Rotate palette to start with green\n",
    "\n",
    "    # Adjust plot size and resolution\n",
    "    plt.figure(figsize=(20, 12), dpi=600)  # Increased plot size\n",
    "\n",
    "    # Initialize a previous sum array to keep track of the cumulative sums\n",
    "    prev_sum = np.zeros(len(reversed_model_names))\n",
    "\n",
    "    # Iterate over each error category in reverse to stack from bottom to top\n",
    "    for error in reversed(errors_of_interest):\n",
    "        current_values = []\n",
    "        for rank in range(len(reversed_model_names)):\n",
    "            if rank in df_sorted[df_sorted['error_category'] == error_title_correction[error]]['model_rank'].values:\n",
    "                current_values.append(df_sorted[(df_sorted['model_rank'] == rank) & (df_sorted['error_category'] == error_title_correction[error])]['avg_error_percentage'].values[0])\n",
    "            else:\n",
    "                current_values.append(0)\n",
    "        current_sum = prev_sum + np.array(current_values)\n",
    "        color = palette[errors_of_interest.index(error)]  # Use the custom palette\n",
    "        plt.fill_between(range(len(reversed_model_names)), prev_sum, current_sum, label=error_title_correction[error], color=color)\n",
    "        prev_sum = current_sum\n",
    "        \n",
    "    # Customize font sizes and styles\n",
    "    plt.xticks(range(len(reversed_model_names)), reversed_model_names, rotation=45, ha=\"right\", fontsize=20, fontweight='bold')\n",
    "    plt.yticks(fontsize=20, fontweight='bold')\n",
    "    plt.xlabel('Model Name', fontsize=20, fontweight='bold')\n",
    "    plt.ylabel('Cumulative Error Percentage', fontsize=20, fontweight='bold')\n",
    "    plt.title('Cumulative Error Analysis by Category', fontsize=23, fontweight='bold')\n",
    "\n",
    "    # Adjust legend to move it further downwards to avoid overlap with the model names\n",
    "    plt.legend(title='Error Category', loc='upper center', bbox_to_anchor=(0.5, -0.3), fancybox=True, shadow=True, ncol=3, fontsize=20, title_fontsize='20')\n",
    "\n",
    "    plt.show()\n",
    "# Assuming df is your DataFrame\n",
    "plot_errors_stacked(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_errors_stacked(df):\n",
    "    errors_of_interest = [\"CompilationError\", \"IdetatioError\", \"SytaxError\", \"NameError\", \"Output Mismatch\", \"Success\", \"Other\"]\n",
    "    error_title_correction = {\n",
    "        \"CompilationError\": \"Compilation Error\",\n",
    "        \"IdetatioError\": \"Indentation Error\",\n",
    "        \"SytaxError\": \"Syntax Error\",\n",
    "        \"NameError\": \"Name Error\",\n",
    "        \"Output Mismatch\": \"Tests Failed\",\n",
    "        \"Success\": \"Test Passed\",\n",
    "    }\n",
    "\n",
    "    df['avg_error_percentage'] = df['error_percentage'].apply(lambda x: float(x.split(' ± ')[0]))\n",
    "    total_by_model = df.groupby('model_name')['avg_error_percentage'].sum().reset_index()\n",
    "    total_by_model['Other'] = 100 - total_by_model['avg_error_percentage']\n",
    "    others_df = total_by_model[['model_name', 'Other']]\n",
    "    others_df['error_category'] = 'Other'\n",
    "    others_df = others_df.rename(columns={'Other': 'avg_error_percentage'})\n",
    "    df = pd.concat([df, others_df[['model_name', 'error_category', 'avg_error_percentage']]])\n",
    "\n",
    "    df['error_category'] = df['error_category'].map(error_title_correction)\n",
    "\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    reversed_model_names = list(model_name_mapping.values())[::-1]\n",
    "    reversed_model_order = {name: i for i, name in enumerate(reversed_model_names)}\n",
    "\n",
    "    df['model_rank'] = df['model_name'].map(model_name_mapping).map(reversed_model_order)\n",
    "\n",
    "    df_sorted = df.sort_values(by=['model_rank', 'error_category'])\n",
    "\n",
    "    sns.set_style(\"white\")\n",
    "    plt.figure(figsize=(20, 12), dpi=600)\n",
    "    plt.gca().set_facecolor('white')  # Change the plot area background to white for contrast\n",
    "\n",
    "    palette = sns.color_palette(\"hls\", len(errors_of_interest))  # Use \"hls\" palette for all categories including \"Other\"\n",
    "\n",
    "    prev_sum = np.zeros(len(reversed_model_names))\n",
    "\n",
    "    for error in reversed(errors_of_interest):\n",
    "        current_values = []\n",
    "        for rank in range(len(reversed_model_names)):\n",
    "            if rank in df_sorted[df_sorted['error_category'] == error]['model_rank'].values:\n",
    "                current_values.append(df_sorted[(df_sorted['model_rank'] == rank) & (df_sorted['error_category'] == error)]['avg_error_percentage'].values[0])\n",
    "            else:\n",
    "                current_values.append(0)\n",
    "        current_sum = prev_sum + np.array(current_values)\n",
    "        color = palette[errors_of_interest.index(error)]\n",
    "        plt.fill_between(range(len(reversed_model_names)), prev_sum, current_sum, label=error, color=color)\n",
    "        prev_sum = current_sum\n",
    "\n",
    "    plt.xticks(range(len(reversed_model_names)), reversed_model_names, rotation=45, ha=\"right\", fontsize=20, fontweight='bold')\n",
    "    plt.yticks(fontsize=20, fontweight='bold')\n",
    "    plt.xlabel('Model Name', fontsize=20, fontweight='bold')\n",
    "    plt.ylabel('Cumulative Error Percentage', fontsize=20, fontweight='bold')\n",
    "    plt.title('Cumulative Error Analysis by Category', fontsize=23, fontweight='bold')\n",
    "\n",
    "    plt.legend(title='Error Category', loc='upper center', bbox_to_anchor=(0.5, -0.2), fancybox=True, shadow=True, ncol=3, fontsize=20, title_fontsize='20')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_errors_stacked(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_errors_stacked(df):\n",
    "    # Correcting typos in error categories and adding \"Others\" category\n",
    "    errors_of_interest = [\"CompilationError\", \"IndentationError\", \"SyntaxError\", \"NameError\", \"Output Mismatch\", \"Success\"]\n",
    "    error_title_correction = {\n",
    "        \"CompilationError\": \"Compilation Error\",\n",
    "        \"IndentationError\": \"Indentation Error\",\n",
    "        \"SyntaxError\": \"Syntax Error\",\n",
    "        \"NameError\": \"Name Error\",\n",
    "        \"Output Mismatch\": \"Tests Failed\",\n",
    "        \"Success\": \"Test Passed\",\n",
    "    }\n",
    "\n",
    "    # Calculate \"Others\" as 100 minus the sum of known errors for each model\n",
    "    df['avg_error_percentage'] = df['error_percentage'].apply(lambda x: float(x.split(' ± ')[0]))\n",
    "    total_by_model = df.groupby('model_name')['avg_error_percentage'].sum().reset_index()\n",
    "    total_by_model['Other'] = 100 - total_by_model['avg_error_percentage']\n",
    "    others_df = total_by_model[['model_name', 'Other']]\n",
    "    others_df['error_category'] = 'Other'\n",
    "    others_df = others_df.rename(columns={'Other': 'avg_error_percentage'})\n",
    "    df = pd.concat([df, others_df[['model_name', 'error_category', 'avg_error_percentage']]])\n",
    "\n",
    "    # Ensure all categories, including \"Other\", are included\n",
    "    errors_of_interest.append(\"Other\")\n",
    "    error_title_correction[\"Other\"] = \"Other\"\n",
    "\n",
    "    # Map error names to their corrected titles\n",
    "    df['error_category'] = df['error_category'].map(error_title_correction)\n",
    "\n",
    "    # Continue with the existing setup\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Reverse the model_name_mapping order\n",
    "    reversed_model_names = list(model_name_mapping.values())[::-1]\n",
    "    reversed_model_order = {name: i for i, name in enumerate(reversed_model_names)}\n",
    "\n",
    "    # Map model names in the DataFrame to their reversed order rank\n",
    "    df['model_rank'] = df['model_name'].map(model_name_mapping).map(reversed_model_order)\n",
    "\n",
    "    # Sort DataFrame by model rank and error category for stacking\n",
    "    df_sorted = df.sort_values(by=['model_rank', 'error_category'])\n",
    "\n",
    "    # Set the style and color palette\n",
    "    sns.set_style(\"white\")\n",
    "    palette = sns.color_palette(\"hls\", len(errors_of_interest))\n",
    "    \n",
    "    # Manually set \"Test Passed\" to green within the palette\n",
    "    test_passed_index = errors_of_interest.index(\"Success\")  # Find the index for \"Test Passed\"\n",
    "    palette[test_passed_index] = (0.4, 0.8, 0.4)  # Set to green\n",
    "\n",
    "    # Adjust plot size and resolution\n",
    "    plt.figure(figsize=(20, 12), dpi=600)\n",
    "\n",
    "    # Plotting without error bars - using fill_between for stacked areas\n",
    "    prev_sum = np.zeros(len(reversed_model_names))\n",
    "    for error in reversed(errors_of_interest):\n",
    "        current_values = []\n",
    "        for rank in range(len(reversed_model_names)):\n",
    "            if rank in df[df['error_category'] == error]['model_rank'].values:\n",
    "                current_values.append(df[(df['model_rank'] == rank) & (df['error_category'] == error)]['avg_error_percentage'].values[0])\n",
    "            else:\n",
    "                current_values.append(0)\n",
    "        current_sum = prev_sum + np.array(current_values)\n",
    "        plt.fill_between(range(len(reversed_model_names)), prev_sum, current_sum, label=error, color=palette[errors_of_interest.index(error)])\n",
    "        prev_sum = current_sum\n",
    "\n",
    "    # Customize font sizes and styles, adjust legend to move it further downwards\n",
    "    plt.xticks(range(len(reversed_model_names)), reversed_model_names, rotation=45, ha=\"right\", fontsize=20, fontweight='bold')\n",
    "    plt.yticks(fontsize=20, fontweight='bold')\n",
    "    plt.xlabel('Model Name', fontsize=20, fontweight='bold')\n",
    "    plt.ylabel('Cumulative Error Percentage', fontsize=20, fontweight='bold')\n",
    "    plt.title('Cumulative Error Analysis by Category', fontsize=23, fontweight='bold')\n",
    "    plt.legend(title='Error Category', loc='upper center', bbox_to_anchor=(0.5, -0.2), fancybox=True, shadow=True, ncol=3, fontsize=20, title_fontsize='20')\n",
    "\n",
    "    plt.show()\n",
    "# Assuming df is your DataFrame\n",
    "plot_errors_stacked(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_errors_stacked(df):\n",
    "    # Adding \"Others\" category\n",
    "    errors_of_interest = [\"CompilationError\", \"IdetatioError\", \"SytaxError\", \"NameError\", \"Output Mismatch\", \"Success\"]\n",
    "    error_title_correction = {\n",
    "        \"CompilationError\": \"Compilation Error\",\n",
    "        \"IdetatioError\": \"Indentation Error\",\n",
    "        \"SytaxError\": \"Syntax Error\",\n",
    "        \"NameError\": \"Name Error\",\n",
    "        \"Output Mismatch\": \"Tests Failed\",\n",
    "        \"Success\": \"Test Passed\",\n",
    "    }\n",
    "\n",
    "    # # Assuming 100% is the total for each model, calculate \"Others\" as 100 minus the sum of known errors\n",
    "    # df['avg_error_percentage'] = df['error_percentage'].apply(lambda x: float(x.split(' ± ')[0]))\n",
    "    # total_by_model = df.groupby('model_name')['avg_error_percentage'].sum().reset_index()\n",
    "    # total_by_model['Others'] = 100 - total_by_model['avg_error_percentage']\n",
    "    # others_df = total_by_model[['model_name', 'Others']]\n",
    "    # others_df['error_category'] = 'Others'\n",
    "    # others_df = others_df.rename(columns={'Others': 'avg_error_percentage'})\n",
    "    # df = pd.concat([df, others_df[['model_name', 'error_category', 'avg_error_percentage']]])\n",
    "\n",
    "    # Calculate \"Others\" as 100 minus the sum of known errors for each model\n",
    "    df['avg_error_percentage'] = df['error_percentage'].apply(lambda x: float(x.split(' ± ')[0]))\n",
    "    total_by_model = df.groupby('model_name')['avg_error_percentage'].sum().reset_index()\n",
    "    total_by_model['Others'] = 100 - total_by_model['avg_error_percentage']\n",
    "    others_df = total_by_model[['model_name', 'Others']]\n",
    "    others_df['error_category'] = 'Others'\n",
    "    others_df = others_df.rename(columns={'Others': 'avg_error_percentage'})\n",
    "    df = pd.concat([df, others_df[['model_name', 'error_category', 'avg_error_percentage']]])\n",
    "\n",
    "    # Map error names to their corrected titles\n",
    "    df['error_category'] = df['error_category'].map(error_title_correction)\n",
    "\n",
    "    # Continue with the existing setup\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Reverse the model_name_mapping order\n",
    "    reversed_model_names = list(model_name_mapping.values())[::-1]\n",
    "    reversed_model_order = {name: i for i, name in enumerate(reversed_model_names)}\n",
    "\n",
    "    # Map model names in the DataFrame to their reversed order rank\n",
    "    df['model_rank'] = df['model_name'].map(model_name_mapping).map(reversed_model_order)\n",
    "\n",
    "    # Sort DataFrame by model rank and error category for stacking\n",
    "    df_sorted = df.sort_values(by=['model_rank', 'error_category'])\n",
    "\n",
    "    # Set the style and color palette\n",
    "    sns.set_style(\"white\")\n",
    "    palette = sns.color_palette(\"hls\", len(errors_of_interest) + 1)  # Adjust palette size for \"Others\"\n",
    "\n",
    "    \n",
    "    # Ensure \"Test Passed\" starts with green by rotating the palette\n",
    "    green_index = palette.index(sns.color_palette(\"hls\", 7)[3])  # Assuming green is at index 2 in the hls palette\n",
    "    palette = palette[green_index:] + palette[:green_index]  # Rotate palette to start with green\n",
    "\n",
    "    # Ensure \"Test Passed\" starts with green\n",
    "    # palette[errors_of_interest.index(\"Success\")] = (0.4, 0.8, 0.4)  # Manually set green for \"Test Passed\"\n",
    "\n",
    "    # Adjust plot size and resolution\n",
    "    plt.figure(figsize=(20, 12), dpi=600)  # Increased plot size\n",
    "\n",
    "    # Initialize a previous sum array to keep track of the cumulative sums\n",
    "    prev_sum = np.zeros(len(reversed_model_names))\n",
    "\n",
    "    # Iterate over each error category in reverse to stack from bottom to top\n",
    "    for error in reversed(errors_of_interest):\n",
    "        current_values = []\n",
    "        for rank in range(len(reversed_model_names)):\n",
    "            if rank in df_sorted[df_sorted['error_category'] == error_title_correction[error]]['model_rank'].values:\n",
    "                current_values.append(df_sorted[(df_sorted['model_rank'] == rank) & (df_sorted['error_category'] == error_title_correction[error])]['avg_error_percentage'].values[0])\n",
    "            else:\n",
    "                current_values.append(0)\n",
    "        current_sum = prev_sum + np.array(current_values)\n",
    "        plt.fill_between(range(len(reversed_model_names)), prev_sum, current_sum, label=error_title_correction[error])\n",
    "        prev_sum = current_sum\n",
    "        \n",
    "    # Customize font sizes and styles\n",
    "    plt.xticks(range(len(reversed_model_names)), reversed_model_names, rotation=45, ha=\"right\", fontsize=20, fontweight='bold')\n",
    "    plt.yticks(fontsize=20, fontweight='bold')\n",
    "    plt.xlabel('Model Name', fontsize=20, fontweight='bold')\n",
    "    plt.ylabel('Cumulative Error Percentage', fontsize=20, fontweight='bold')\n",
    "    plt.title('Cumulative Error Analysis by Category', fontsize=23, fontweight='bold')\n",
    "\n",
    "    # Adjust legend to move it further downwards\n",
    "    # plt.legend(title='Error Category', loc='upper center', bbox_to_anchor=(0.5, -0.2), fancybox=True, shadow=True, ncol=3, fontsize=20, title_fontsize='20')\n",
    "    plt.legend(title='Error Category', loc='upper center', bbox_to_anchor=(0.5, -0.3), fancybox=True, shadow=True, ncol=3, fontsize=20, title_fontsize='20')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "plot_errors_stacked(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import re\n",
    "\n",
    "all_w_post_process = '../Analysis_Results/storage_server/All_models_res/post_process/all_post.csv'\n",
    "all_no_post_process = '../Analysis_Results/storage_server/All_models_res/post_process/all_no_post.csv' \n",
    "df_post = pd.read_csv(all_w_post_process)\n",
    "df_no_post = pd.read_csv(all_no_post_process)\n",
    "df_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def plot_all_pass_ratio(df):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Original model names and their simplified display names\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Simplify model names in the DataFrame\n",
    "    df['model_display_name'] = df['Model Name'].map(model_name_mapping)\n",
    "\n",
    "    # Define a fixed color palette for all display models\n",
    "    palette = sns.color_palette(\"husl\", len(model_name_mapping))\n",
    "\n",
    "    # Map each display model to a color\n",
    "    model_color_map = {display_name: color for display_name, color in zip(model_name_mapping.values(), palette)}\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for model_display_name, group in df.groupby('model_display_name'):\n",
    "        plt.errorbar(group['model_display_name'], group['All Pass Ratio (%)'], yerr=group['Error Bar'], fmt='o', color=model_color_map[model_display_name], label=model_display_name)\n",
    "\n",
    "    # sns.barplot(x='model_display_name', y='avg_error_percentage', data=df, ax=ax, palette=model_color_map, yerr=df['Error Bar'])\n",
    "    plt.ylabel('All Pass Ratio (%)', fontsize=14)\n",
    "    plt.title('All Pass Ratio (%) by Model with Error Bars', fontsize=16)\n",
    "    plt.xticks(rotation=45, ha=\"right\", fontsize=12)\n",
    "\n",
    "    # Update legend handles for display model names\n",
    "    legend_handles = [mpatches.Patch(color=model_color_map[display_name], label=display_name) for display_name in model_name_mapping.values()]\n",
    "    plt.legend(handles=legend_handles, title=\"Model Names\", loc='upper right', fancybox=True, shadow=True, fontsize=12, title_fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "plot_all_pass_ratio(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def plot_all_pass_ratio_bar_chart(df):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Original model names and their simplified display names\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Simplify model names in the DataFrame\n",
    "    df['model_display_name'] = df['Model Name'].map(model_name_mapping)\n",
    "\n",
    "    # Define a fixed color palette for all display models\n",
    "    palette = sns.color_palette(\"husl\", len(model_name_mapping))\n",
    "\n",
    "    # Create a figure for the plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Plotting\n",
    "    sns.barplot(x='model_display_name', y='All Pass Ratio (%)', data=df, palette=palette, ci=None, ax=ax)\n",
    "\n",
    "    # Manually add error bars\n",
    "    for index, row in df.iterrows():\n",
    "        plt.errorbar(x=index, y=row['All Pass Ratio (%)'], yerr=row['Error Bar'], fmt='none', color='black', capsize=5)\n",
    "\n",
    "    ax.set_ylabel('All Pass Ratio (%)', fontsize=14)\n",
    "    ax.set_title('All Pass Ratio (%) by Model with Error Bars', fontsize=16)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=12)\n",
    "\n",
    "    # Update legend handles for display model names\n",
    "    legend_handles = [mpatches.Patch(color=color, label=display_name) for display_name, color in zip(model_name_mapping.values(), palette)]\n",
    "\n",
    "    # Add the legend to the figure instead of the last subplot\n",
    "    fig.legend(handles=legend_handles, title=\"Model Names\", loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=5, fontsize=20, title_fontsize=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "plot_all_pass_ratio_bar_chart(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Specific order for the models\n",
    "model_order = [\n",
    "    \"gpt-4-turbo\", \"claude-3-opus-20240229\", \"claude-3-sonnet-20240229\", \n",
    "    \"claude-3-haiku-20240307\", \"Meta-Llama-3-70B-Instruct\", \"gpt-3.5-turbo-0125\",\n",
    "    \"Meta-Llama-3-8B-Instruct\", \"deepseek-coder-7b-instruct\", \"deepseek-coder-1.3b-instruct\", \n",
    "    \"phi-3-mini-4k\"\n",
    "]\n",
    "\n",
    "def plot_all_pass_ratio_bar_chart_ordered(df, model_order):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Original model names and their simplified display names\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Simplify model names in the DataFrame\n",
    "    df['model_display_name'] = df['Model Name'].map(model_name_mapping)\n",
    "\n",
    "    # Define a fixed color palette for all display models\n",
    "    palette = sns.color_palette(\"husl\", len(model_name_mapping))\n",
    "\n",
    "    # Create a figure for the plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Plotting with specified order\n",
    "    sns.barplot(x='model_display_name', y='All Pass Ratio (%)', data=df, palette=palette, ci=None, ax=ax, order=[model_name_mapping[model] for model in model_order])\n",
    "\n",
    "    # Manually add error bars\n",
    "    for index, row in df[df['Model Name'].isin(model_order)].iterrows():\n",
    "        plt.errorbar(x=model_order.index(row['Model Name']), y=row['All Pass Ratio (%)'], yerr=row['Error Bar'], fmt='none', color='black', capsize=5)\n",
    "\n",
    "    ax.set_ylabel('All Pass Ratio (%)', fontsize=14)\n",
    "    ax.set_title('All Pass Ratio (%) by Model with Error Bars', fontsize=16)\n",
    "    ax.set_xticklabels([model_name_mapping[model] for model in model_order], rotation=45, ha=\"right\", fontsize=12)\n",
    "\n",
    "    # Update legend handles for display model names\n",
    "    legend_handles = [mpatches.Patch(color=color, label=model_name_mapping[model]) for model, color in zip(model_order, palette)]\n",
    "\n",
    "    # Add the legend to the figure instead of the last subplot\n",
    "    fig.legend(handles=legend_handles, title=\"Model Names\", loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=5, fontsize=12, title_fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'model_order' is defined as above\n",
    "plot_all_pass_ratio_bar_chart_ordered(df_no_post, model_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "\n",
    "# Specific order for the models\n",
    "model_order = [\n",
    "    \"gpt-4-turbo\", \"claude-3-opus-20240229\", \"claude-3-sonnet-20240229\", \n",
    "    \"claude-3-haiku-20240307\", \"Meta-Llama-3-70B-Instruct\", \"gpt-3.5-turbo-0125\",\n",
    "    \"Meta-Llama-3-8B-Instruct\", \"deepseek-coder-7b-instruct\", \"deepseek-coder-1.3b-instruct\", \n",
    "    \"phi-3-mini-4k\"\n",
    "]\n",
    "\n",
    "def plot_all_pass_ratio_side_by_side(df_no_post, df_post, model_order):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Original model names and their simplified display names\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Simplify model names in the DataFrames\n",
    "    df_no_post['model_display_name'] = df_no_post['Model Name'].map(model_name_mapping)\n",
    "    df_post['model_display_name'] = df_post['Model Name'].map(model_name_mapping)\n",
    "\n",
    "    # Merge the two DataFrames for easier plotting\n",
    "    df_no_post['Type'] = 'No Post-Processing'\n",
    "    df_post['Type'] = 'With Post-Processing'\n",
    "    df_combined = pd.concat([df_no_post, df_post])\n",
    " \n",
    "    # Define a color palette for 'No Post' and 'Post'\n",
    "    palette = sns.color_palette(\"husl\", 2)  # Only two types: 'No Post' and 'Post'\n",
    "    lighter_color, darker_color = palette\n",
    "\n",
    "    # Simplify the combined_palette to match 'Type' values directly\n",
    "    combined_palette = {'No Post-Processing': lighter_color, 'With Post-Processing': darker_color}\n",
    "\n",
    "\n",
    "    # # Create a figure for the plot with increased resolution\n",
    "    fig, ax = plt.subplots(figsize=(12, 9), dpi=400)\n",
    "\n",
    "    # Plotting with specified order and side by side bars\n",
    "    sns.barplot(x='model_display_name', y='All Pass Ratio (%)', hue='Type', data=df_combined, palette=combined_palette, ci=None, ax=ax, order=[model_name_mapping[model] for model in model_order])\n",
    "    \n",
    "    ax.set_ylabel('All Pass Ratio (%)', fontsize=14)\n",
    "    ax.set_title('All Pass Ratio (%) by Model with and without Post Processing', fontsize=16)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=12)\n",
    "\n",
    "    # Update legend handles for display model names with type\n",
    "    legend_handles = [mpatches.Patch(color=color, label=model) for model, color in combined_palette.items()]\n",
    "\n",
    "    # Add the legend to the figure instead of the last subplot\n",
    "    fig.legend(handles=legend_handles, title=\"Types\", loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=5, fontsize=12, title_fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'df_no_post' and 'df_post' are your DataFrames and 'model_order' is defined as above\n",
    "plot_all_pass_ratio_side_by_side(df_no_post, df_post, model_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "\n",
    "# Specific order for the models\n",
    "model_order = [\n",
    "    \"gpt-4-turbo\", \"claude-3-opus-20240229\", \"claude-3-sonnet-20240229\", \n",
    "    \"claude-3-haiku-20240307\", \"Meta-Llama-3-70B-Instruct\", \"gpt-3.5-turbo-0125\",\n",
    "    \"Meta-Llama-3-8B-Instruct\", \"deepseek-coder-7b-instruct\", \"deepseek-coder-1.3b-instruct\", \n",
    "    \"phi-3-mini-4k\"\n",
    "]\n",
    "\n",
    "def plot_all_pass_ratio_side_by_side(df_no_post, df_post, model_order):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Original model names and their simplified display names\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Simplify model names in the DataFrames\n",
    "    df_no_post['model_display_name'] = df_no_post['Model Name'].map(model_name_mapping)\n",
    "    df_post['model_display_name'] = df_post['Model Name'].map(model_name_mapping)\n",
    "\n",
    "    # Combine the two DataFrames with an additional 'Condition' column\n",
    "    df_no_post['Condition'] = 'No Post'\n",
    "    df_post['Condition'] = 'Post'\n",
    "    df_combined = pd.concat([df_no_post, df_post], ignore_index=True)\n",
    "\n",
    "\n",
    "    # # Define a color palette with lighter colors for 'No Post' and darker colors for 'Post'\n",
    "    # palette = sns.color_palette(\"husl\", len(model_order))\n",
    "    # lighter_colors = sns.color_palette([(r, g, b, 0.6) for r, g, b in palette])\n",
    "    # darker_colors = sns.color_palette([(r, g, b, 1) for r, g, b in palette])\n",
    "    # combined_palette = {model_name_mapping[model] + ' No Post': lighter_colors[i] for i, model in enumerate(model_order)}\n",
    "    # combined_palette.update({model_name_mapping[model] + ' Post': darker_colors[i] for i, model in enumerate(model_order)})\n",
    "    \n",
    "    # Define a base color palette for all display models\n",
    "    base_palette = sns.color_palette(\"husl\", len(model_order))\n",
    "\n",
    "\n",
    "    # Generate darker and lighter shades for each model\n",
    "    # This is a simplified approach; adjust the color manipulation as needed\n",
    "    colors = {}\n",
    "    for i, model in enumerate(model_order):\n",
    "        base_color = base_palette[i]\n",
    "        # Assuming base_color is in RGB format\n",
    "        darker = sns.dark_palette(base_color, n_colors=3)[2]  # Get a darker shade\n",
    "        lighter = sns.light_palette(base_color, n_colors=3)[1]  # Get a lighter shade\n",
    "        colors[model] = {'Post': darker, 'No Post': lighter}\n",
    "    \n",
    "    # Create a mapping for colors to use in the plot\n",
    "    color_mapping = {model_name_mapping[model] + ' - ' + condition: colors[model][condition] for model in model_order for condition in ['Post', 'No Post']}\n",
    "\n",
    "    # Simplify model names in the DataFrame\n",
    "    df_combined['model_display_name'] = df_combined['Model Name'].map(model_name_mapping) + ' - ' + df_combined['Condition']\n",
    "\n",
    "\n",
    "    # # Create a figure for the plot with increased resolution\n",
    "    fig, ax = plt.subplots(figsize=(12, 9), dpi=400)\n",
    "    sns.barplot(x='model_display_name', y='All Pass Ratio (%)', data=df_combined, palette=color_mapping, ci=None, ax=ax)\n",
    "\n",
    "    # Manually add error bars\n",
    "    # Adjust this loop to correctly place error bars for \"Post\" and \"No Post\"\n",
    "    for index, row in df_combined.iterrows():\n",
    "        model_index = model_order.index(row['Model Name']) * 2 + ('Post' == row['Condition'])\n",
    "        plt.errorbar(x=model_index, y=row['All Pass Ratio (%)'], yerr=row['Error Bar'], fmt='none', color='black', capsize=5)\n",
    "\n",
    "    ax.set_ylabel('All Pass Ratio (%)', fontsize=14)\n",
    "    ax.set_title('All Pass Ratio (%) by Model with Error Bars', fontsize=16)\n",
    "    ax.set_xticklabels(color_mapping.keys(), rotation=45, ha=\"right\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # # Plotting with specified order and side by side bars\n",
    "    # # sns.barplot(x='model_display_name', y='All Pass Ratio (%)', hue='Type', data=df_combined, palette=combined_palette, ci=None, ax=ax, order=[model_name_mapping[model] for model in model_order])\n",
    "    # sns.barplot(x='model_display_name', y='All Pass Ratio (%)', hue='Type', data=df_combined, palette=combined_palette, ci=None, ax=ax, order=[model_name_mapping[model] for model in model_order])\n",
    "    \n",
    "    # ax.set_ylabel('All Pass Ratio (%)', fontsize=14)\n",
    "    # ax.set_title('All Pass Ratio (%) by Model with and without Post Processing', fontsize=16)\n",
    "    # ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=12)\n",
    "\n",
    "    # # Update legend handles for display model names with type\n",
    "    # legend_handles = [mpatches.Patch(color=color, label=model) for model, color in combined_palette.items()]\n",
    "\n",
    "    # # Add the legend to the figure instead of the last subplot\n",
    "    # fig.legend(handles=legend_handles, title=\"Model Names and Types\", loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=5, fontsize=12, title_fontsize=14)\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "# Assuming 'df_no_post' and 'df_post' are your DataFrames and 'model_order' is defined as above\n",
    "plot_all_pass_ratio_side_by_side(df_no_post, df_post, model_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "\n",
    "# Specific order for the models\n",
    "model_order = [\n",
    "    \"gpt-4-turbo\", \"claude-3-opus-20240229\", \"claude-3-sonnet-20240229\", \n",
    "    \"claude-3-haiku-20240307\", \"Meta-Llama-3-70B-Instruct\", \"gpt-3.5-turbo-0125\",\n",
    "    \"Meta-Llama-3-8B-Instruct\", \"deepseek-coder-7b-instruct\", \"deepseek-coder-1.3b-instruct\", \n",
    "    \"phi-3-mini-4k\"\n",
    "]\n",
    "\n",
    "def plot_all_pass_ratio_side_by_side(df_no_post, df_post, model_order):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Original model names and their simplified display names\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Simplify model names in the DataFrames\n",
    "    df_no_post['model_display_name'] = df_no_post['Model Name'].map(model_name_mapping)\n",
    "    df_post['model_display_name'] = df_post['Model Name'].map(model_name_mapping)\n",
    "\n",
    "    # Merge the two DataFrames for easier plotting\n",
    "    df_no_post['Type'] = 'No Post'\n",
    "    df_post['Type'] = 'Post'\n",
    "    df_combined = pd.concat([df_no_post, df_post])\n",
    "\n",
    "    # # Define a color palette with lighter colors for 'No Post' and darker colors for 'Post'\n",
    "    # palette = sns.color_palette(\"husl\", len(model_order))\n",
    "    # lighter_colors = sns.color_palette([(r, g, b, 0.6) for r, g, b in palette])\n",
    "    # darker_colors = sns.color_palette([(r, g, b, 1) for r, g, b in palette])\n",
    "    # combined_palette = {model_name_mapping[model] + ' No Post': lighter_colors[i] for i, model in enumerate(model_order)}\n",
    "    # combined_palette.update({model_name_mapping[model] + ' Post': darker_colors[i] for i, model in enumerate(model_order)})\n",
    "    \n",
    "    # Define a color palette for 'No Post' and 'Post'\n",
    "    palette = sns.color_palette(\"husl\", 2)  # Only two types: 'No Post' and 'Post'\n",
    "    lighter_color, darker_color = palette\n",
    "\n",
    "    # Simplify the combined_palette to match 'Type' values directly\n",
    "    combined_palette = {'No Post': lighter_color, 'Post': darker_color}\n",
    "\n",
    "\n",
    "    # # Create a figure for the plot with increased resolution\n",
    "    fig, ax = plt.subplots(figsize=(12, 9), dpi=400)\n",
    "\n",
    "    # Plotting with specified order and side by side bars\n",
    "    # sns.barplot(x='model_display_name', y='All Pass Ratio (%)', hue='Type', data=df_combined, palette=combined_palette, ci=None, ax=ax, order=[model_name_mapping[model] for model in model_order])\n",
    "    sns.barplot(x='model_display_name', y='All Pass Ratio (%)', hue='Type', data=df_combined, palette=combined_palette, ci=None, ax=ax, order=[model_name_mapping[model] for model in model_order])\n",
    "    \n",
    "    ax.set_ylabel('All Pass Ratio (%)', fontsize=14)\n",
    "    ax.set_title('All Pass Ratio (%) by Model with and without Post Processing', fontsize=16)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=12)\n",
    "\n",
    "    # Update legend handles for display model names with type\n",
    "    legend_handles = [mpatches.Patch(color=color, label=model) for model, color in combined_palette.items()]\n",
    "\n",
    "    # Add the legend to the figure instead of the last subplot\n",
    "    fig.legend(handles=legend_handles, title=\"Types\", loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=5, fontsize=12, title_fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'df_no_post' and 'df_post' are your DataFrames and 'model_order' is defined as above\n",
    "plot_all_pass_ratio_side_by_side(df_no_post, df_post, model_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import re\n",
    "\n",
    "all_w_post_process = '../Analysis_Results/storage_server/All_models_res/post_process/all_post.csv'\n",
    "all_no_post_process = '../Analysis_Results/storage_server/All_models_res/post_process/all_no_post.csv' \n",
    "python_w_post_process = '../Analysis_Results/storage_server/All_models_res/post_process/python_res_with_post.csv'\n",
    "python_no_post_process = '../Analysis_Results/storage_server/All_models_res/post_process/python_res_no_post.csv' \n",
    "java_w_post_process = '../Analysis_Results/storage_server/All_models_res/post_process/java_res_with_post.csv'\n",
    "java_no_post_process = '../Analysis_Results/storage_server/All_models_res/post_process/java_res_no_post.csv' \n",
    "df_post = pd.read_csv(all_w_post_process)\n",
    "df_no_post = pd.read_csv(all_no_post_process)\n",
    "python_w_post = pd.read_csv(python_w_post_process)\n",
    "python_no_post = pd.read_csv(python_no_post_process)\n",
    "java_w_post = pd.read_csv(java_w_post_process)\n",
    "java_no_post = pd.read_csv(java_no_post_process)\n",
    "display(python_w_post)\n",
    "display(python_no_post)\n",
    "display(java_w_post)\n",
    "display(java_no_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific order for the models\n",
    "model_order = [\n",
    "    \"gpt-4-turbo\", \"claude-3-opus-20240229\", \"claude-3-sonnet-20240229\", \n",
    "    \"claude-3-haiku-20240307\", \"Meta-Llama-3-70B-Instruct\", \"gpt-3.5-turbo-0125\",\n",
    "    \"Meta-Llama-3-8B-Instruct\", \"deepseek-coder-7b-instruct\", \"deepseek-coder-1.3b-instruct\", \n",
    "    \"phi-3-mini-4k\"\n",
    "]\n",
    "\n",
    "def plot_all_pass_ratio_side_by_side(df_no_post, df_post, model_order, program_type):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Original model names and their simplified display names\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Simplify model names in the DataFrames\n",
    "    df_no_post['model_display_name'] = df_no_post['Model Name'].map(model_name_mapping)\n",
    "    df_post['model_display_name'] = df_post['Model Name'].map(model_name_mapping)\n",
    "\n",
    "    # Merge the two DataFrames for easier plotting\n",
    "    df_no_post['Type'] = 'No Post-Processing'\n",
    "    df_post['Type'] = 'With Post-Processing'\n",
    "    df_combined = pd.concat([df_no_post, df_post])\n",
    "\n",
    "    # Define a color palette for 'No Post' and 'Post'\n",
    "    palette = sns.color_palette(\"husl\", 2)  # Only two types: 'No Post' and 'Post'\n",
    "    lighter_color, darker_color = palette\n",
    "\n",
    "    # Simplify the combined_palette to match 'Type' values directly\n",
    "    combined_palette = {'No Post-Processing': lighter_color, 'With Post-Processing': darker_color}\n",
    "\n",
    "    # Create a figure for the plot with increased resolution\n",
    "    fig, ax = plt.subplots(figsize=(12, 9), dpi=400)\n",
    "\n",
    "    # Plotting with specified order and side by side bars\n",
    "    sns.barplot(x='model_display_name', y='All Pass Ratio (%)', hue='Type', data=df_combined, palette=combined_palette, ci=None, ax=ax, order=[model_name_mapping[model] for model in model_order])\n",
    "\n",
    "    # Updated title with program_type included, x-axis, and y-axis labels\n",
    "    ax.set_title(f'{program_type} - Pass Rate with vs. without Post-Processing', fontsize=23)\n",
    "    ax.set_ylabel('Percentage', fontsize=20)\n",
    "    # ax.set_xlabel('Model Name', fontsize=20)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=15)\n",
    "\n",
    "    # Remove the default legend\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "    # Update legend handles for display model names with type and place it at the bottom center\n",
    "    legend_handles = [mpatches.Patch(color=color, label=label) for label, color in combined_palette.items()]\n",
    "    # fig.legend(handles=legend_handles, loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=5, fontsize=15, title_fontsize=20)\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # # Save the plot with program_type in the filename\n",
    "    # plt.savefig(f'{program_type}_pass_rate_comparison.png')\n",
    "    # plt.show()\n",
    "    \n",
    "    # Adjust the legend placement to be within the figure bounds\n",
    "    # fig.legend(handles=legend_handles, loc='lower center', bbox_to_anchor=(0.5, 0.01), fancybox=True, shadow=True, ncol=5, fontsize=15, title_fontsize=20)\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=True, ncol=3)\n",
    "    \n",
    "    # Adjust tight_layout to make space for the legend outside the plot area\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot with program_type in the filename\n",
    "    plt.savefig(f'{program_type}_pass_rate_comparison.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_all_pass_ratio_side_by_side(python_no_post, python_w_post, model_order, \"Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_pass_ratio_side_by_side(java_no_post, java_w_post, model_order, \"Java\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {\n",
    "    'Python': (python_no_post, python_w_post),\n",
    "    'Java': (java_no_post, java_w_post)\n",
    "}\n",
    "\n",
    "def plot_pass_ratio_for_program_types_combined(df_dict, model_order):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Define program types and their respective data\n",
    "    program_types = ['Python', 'Java']\n",
    "\n",
    "    # Original model names and their simplified display names\n",
    "    model_name_mapping = {\n",
    "        \"gpt-4-turbo\": \"GPT-4 Turbo\",\n",
    "        \"claude-3-opus-20240229\": \"Claude-3 Opus\",\n",
    "        \"claude-3-sonnet-20240229\": \"Claude-3 Sonnet\",\n",
    "        \"claude-3-haiku-20240307\": \"Claude-3 Haiku\",\n",
    "        \"Meta-Llama-3-70B-Instruct\": \"Meta-Llama-3 70B\",\n",
    "        \"gpt-3.5-turbo-0125\": \"GPT-3.5 Turbo\",\n",
    "        \"Meta-Llama-3-8B-Instruct\": \"Meta-Llama-3 8B\",\n",
    "        \"deepseek-coder-7b-instruct\": \"DeepSeek Coder 7B\",\n",
    "        \"deepseek-coder-1.3b-instruct\": \"DeepSeek Coder 1.3B\",\n",
    "        \"phi-3-mini-4k\": \"Phi-3 Mini 4K\"\n",
    "    }\n",
    "\n",
    "    # Create subplots for each program type\n",
    "    fig, axs = plt.subplots(len(program_types), 1, figsize=(12, 18), dpi=400)\n",
    "\n",
    "    for i, program_type in enumerate(program_types):\n",
    "        df_no_post, df_post = df_dict[program_type]\n",
    "\n",
    "        # Simplify model names in the DataFrames\n",
    "        df_no_post['model_display_name'] = df_no_post['Model Name'].map(model_name_mapping)\n",
    "        df_post['model_display_name'] = df_post['Model Name'].map(model_name_mapping)\n",
    "\n",
    "        # Merge the two DataFrames for easier plotting\n",
    "        df_no_post['Type'] = 'No Post-Processing'\n",
    "        df_post['Type'] = 'With Post-Processing'\n",
    "        df_combined = pd.concat([df_no_post, df_post])\n",
    "\n",
    "        # Define a color palette for 'No Post' and 'Post'\n",
    "        palette = sns.color_palette(\"husl\", 2)  # Only two types: 'No Post' and 'Post'\n",
    "        combined_palette = {'No Post-Processing': palette[0], 'With Post-Processing': palette[1]}\n",
    "\n",
    "        ax = axs[i]\n",
    "        # Plotting with specified order and side by side bars\n",
    "        sns.barplot(x='model_display_name', y='All Pass Ratio (%)', hue='Type', data=df_combined, palette=combined_palette, ci=None, ax=ax, order=[model_name_mapping[model] for model in model_order])\n",
    "\n",
    "        # Set title, x-axis, and y-axis labels\n",
    "        ax.set_title(f'{program_type} - Pass Rate with vs. without Post-Processing', fontsize=16)\n",
    "        ax.set_ylabel('Percentage', fontsize=14)\n",
    "        ax.set_xlabel('Model Name', fontsize=14)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=12)\n",
    "\n",
    "        # Remove the default legend for all but the last plot\n",
    "        if i < len(program_types) - 1:\n",
    "            ax.get_legend().remove()\n",
    "\n",
    "    # Update legend handles for display model names with type and place it at the bottom center of the last plot\n",
    "    legend_handles = [mpatches.Patch(color=color, label=label) for label, color in combined_palette.items()]\n",
    "    axs[-1].legend(handles=legend_handles, loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=5, fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Save the plot with combined program types in the filename\n",
    "    plt.savefig('Python & Java_pass_rate_comparison.png')\n",
    "    plt.show()\n",
    "\n",
    "plot_pass_ratio_for_program_types_combined(df_dict, model_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t5_infer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
